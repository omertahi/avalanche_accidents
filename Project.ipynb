{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d96d97-1623-467a-861b-633e9e47ba54",
   "metadata": {},
   "source": [
    "# Investigation of Avalanche Tendencies:\n",
    "## Authors: Lucas Crichton, Omer Tahir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7eefaf-0071-48d0-92b0-3aea0f8da554",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "## Introduction\n",
    "Within this investigation, data from North America and Europe was explored to reveal potential trends among avalanche occurrences. The data used was provided by Avalanche Canada,the Colorado Avalanche Information Center (CAIC) and European Avalanche Warning Services (EAWS). Firstly, an exploratory analysis will be conducted to investigate the relationship between the type of activity performed at the time of the avalanches and the number of deaths caused by the avalanches. Next We will investigate whether the number of avalanche deaths are relatively even throughout the ski season or whether there is a time of the year where deadly avalanches are more common. \n",
    "\n",
    "## Sources:\n",
    "- “Avalanche.org \" Accidents.” Avalanche.org, Colorado Avalanche Information Center, 5 Feb. 2020, https://avalanche.org/avalanche-accidents/. \n",
    "- “Fatalities.” EAWS, 25 Nov. 2021, https://www.avalanches.org/fatalities/fatalities-20/. \n",
    "- “Historical Incidents.” Avalanche Canada, https://www.avalanche.ca/incidents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6ceac-53bb-4bcb-9244-b407e0b89ca2",
   "metadata": {},
   "source": [
    "## Preparing the Data:\n",
    "firstly, we must prepare the data so that our data frame for our analysis contains data from all 3 sources and all necessary variables.\n",
    "\n",
    "## Installing Necessary Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f8f62b8b-e369-4ca9-98d2-52c0186a5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import warnings\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564970ec-8d5b-4bf0-8498-3f28efb63451",
   "metadata": {},
   "source": [
    "## Scraping Data off the web\n",
    "\n",
    "We will begin by scraping data for avalanche accidents across different regions such as Canada, the United States and Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfbfbc-40af-48bf-a5be-638a1035aba9",
   "metadata": {},
   "source": [
    "### Avalanche Data (Canada):\n",
    "\n",
    "* Scrape the Canada avalanche data from the url.\n",
    "* With the help of the package `urllib`, extract the page source and decode it.\n",
    "* The result is a list of dictionary objects which are combined to form a single DataFrame.\n",
    "* The `id` column of the DataFrame gives access to further information for each observation. This information is extracted and added as columns to form a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8e63caa3-c578-4059-a615-e950c3da1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ob_date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_desc</th>\n",
       "      <th>location_coords</th>\n",
       "      <th>location_coords_type</th>\n",
       "      <th>location_elevation</th>\n",
       "      <th>location_province</th>\n",
       "      <th>num_involved</th>\n",
       "      <th>num_injured</th>\n",
       "      <th>num_fatal</th>\n",
       "      <th>comment</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>avalanche_obs</th>\n",
       "      <th>weather_obs</th>\n",
       "      <th>weather_comment</th>\n",
       "      <th>snowpack_obs</th>\n",
       "      <th>snowpack_comment</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bc4720d-498c-4793-81ef-c43db9f36ca4</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>Approx. 17km East of Powder King ski area</td>\n",
       "      <td>[55.366223, -122.34096]</td>\n",
       "      <td>Lat/lng</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of four were snowmobiling in Sunshine ...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>[{'size': '3.0', 'type': 'S', 'trigger': 'Ma',...</td>\n",
       "      <td>{'temp_present': None, 'temp_max': None, 'temp...</td>\n",
       "      <td>Overcast, windy conditions were reported with ...</td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td>A snow profile near the avalanche on the follo...</td>\n",
       "      <td>[{'date': '2021-11-30', 'title': 'Scene photo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3a4698-d047-4082-bdea-92f4db7e63bf</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>Approximately 96km SE of Jasper</td>\n",
       "      <td>[52.17836, -117.24785]</td>\n",
       "      <td>Lat/lng</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A party of two people were climbing the Skylad...</td>\n",
       "      <td>Mountaineering</td>\n",
       "      <td>[{'size': '2.5', 'type': 'S', 'trigger': 'Sa',...</td>\n",
       "      <td>{'temp_present': None, 'temp_max': 8.0, 'temp_...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-06-01', 'title': 'Mt Andromeda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba14a125-29f7-4432-97ad-73a53207a5e7</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>Approximately 6km SW of Lake Louise Village</td>\n",
       "      <td>[51.38329, -116.23453]</td>\n",
       "      <td>Lat/lng</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of two people were ski touring up the ...</td>\n",
       "      <td>Skiing</td>\n",
       "      <td>[{'size': '2.0', 'type': 'S', 'trigger': 'Sa',...</td>\n",
       "      <td>{'temp_present': None, 'temp_max': None, 'temp...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-04-05', 'title': 'Overview pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id     ob_date  \\\n",
       "0  8bc4720d-498c-4793-81ef-c43db9f36ca4  2021-11-27   \n",
       "1  6a3a4698-d047-4082-bdea-92f4db7e63bf  2021-05-30   \n",
       "2  ba14a125-29f7-4432-97ad-73a53207a5e7  2021-04-05   \n",
       "\n",
       "                     location                                location_desc  \\\n",
       "0  Sunshine Bowl, Hasler Area    Approx. 17km East of Powder King ski area   \n",
       "1   Mount Andromeda-Skyladder              Approximately 96km SE of Jasper   \n",
       "2                  Haddo Peak  Approximately 6km SW of Lake Louise Village   \n",
       "\n",
       "           location_coords location_coords_type  location_elevation  \\\n",
       "0  [55.366223, -122.34096]              Lat/lng              1700.0   \n",
       "1   [52.17836, -117.24785]              Lat/lng              3075.0   \n",
       "2   [51.38329, -116.23453]              Lat/lng              2950.0   \n",
       "\n",
       "  location_province  num_involved  num_injured  num_fatal  \\\n",
       "0                BC           3.0          0.0          1   \n",
       "1                AB           2.0          0.0          2   \n",
       "2                AB           2.0          0.0          1   \n",
       "\n",
       "                                             comment  group_activity  \\\n",
       "0  A party of four were snowmobiling in Sunshine ...    Snowmobiling   \n",
       "1  A party of two people were climbing the Skylad...  Mountaineering   \n",
       "2  A party of two people were ski touring up the ...          Skiing   \n",
       "\n",
       "                                       avalanche_obs  \\\n",
       "0  [{'size': '3.0', 'type': 'S', 'trigger': 'Ma',...   \n",
       "1  [{'size': '2.5', 'type': 'S', 'trigger': 'Sa',...   \n",
       "2  [{'size': '2.0', 'type': 'S', 'trigger': 'Sa',...   \n",
       "\n",
       "                                         weather_obs  \\\n",
       "0  {'temp_present': None, 'temp_max': None, 'temp...   \n",
       "1  {'temp_present': None, 'temp_max': 8.0, 'temp_...   \n",
       "2  {'temp_present': None, 'temp_max': None, 'temp...   \n",
       "\n",
       "                                     weather_comment  \\\n",
       "0  Overcast, windy conditions were reported with ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "\n",
       "                                        snowpack_obs  \\\n",
       "0  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "1  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "2  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "\n",
       "                                    snowpack_comment  \\\n",
       "0  A snow profile near the avalanche on the follo...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "\n",
       "                                           documents  \n",
       "0  [{'date': '2021-11-30', 'title': 'Scene photo'...  \n",
       "1  [{'date': '2021-06-01', 'title': 'Mt Andromeda...  \n",
       "2  [{'date': '2021-04-05', 'title': 'Overview pho...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Incidents\n",
    "url = \"http://incidents.avalanche.ca/public/incidents/?format=json\"\n",
    "req = urllib.request.Request(url)\n",
    "\n",
    "with urllib.request.urlopen(req) as response:\n",
    "    result = json.loads(response.read().decode('utf-8'))\n",
    "incident_list = result[\"results\"]\n",
    "\n",
    "while (result[\"next\"] != None):\n",
    "    req = urllib.request.Request(result[\"next\"])\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "    incident_list = incident_list + result[\"results\"]\n",
    "incidents_brief = pd.DataFrame.from_dict(incident_list,orient=\"columns\")\n",
    "\n",
    "# We can get more information about these incidents e.g. \"https://www.avalanche.ca/incidents/37d909e4-c6de-43f1-8416-57a34cd48255\"\n",
    "# this information is also available through the API\n",
    "def get_incident_details(id):\n",
    "    url = \"http://incidents.avalanche.ca/public/incidents/{}?format=json\".format(id)\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "    return(result)\n",
    "\n",
    "incidentsfile = \"https://datascience.quantecon.org/assets/data/avalanche_incidents.csv\"\n",
    "\n",
    "# To avoid loading the avalanche Canada servers, we save the incident details locally.\n",
    "if (not os.path.isfile(incidentsfile)):\n",
    "    incident_detail_list = incidents_brief.id.apply(get_incident_details).to_list()\n",
    "    incidents = pd.DataFrame.from_dict(incident_detail_list, orient=\"columns\")\n",
    "    incidents.to_csv(incidentsfile)\n",
    "else:\n",
    "    incidents = pd.read_csv(incidentsfile)\n",
    "    \n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(incidents.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2dacb-ed62-4a6f-ab18-43aab9740747",
   "metadata": {},
   "source": [
    "#### Data Wrangling on Avalanche Data (Canada)\n",
    "\n",
    "* Begin by renaming the categories in the `group_activity` column to increase interpretability. For this, we define a custom function called `clean_group_activity()` which will be used for other dataframes as well.\n",
    "* Next, extract one of the dataframes nested inside a column of the `incidents` dataframe.\n",
    "* Concat the `group_activity` column to the `cleaned_incidents` dataframe.\n",
    "* Select only the useful columns from `incidents` dataframe and merge it with the `cleaned_incidents` dataframe to create the `ca_incidents` dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5607f588-c957-43d9-a66e-01995594b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>state/province</th>\n",
       "      <th>involved</th>\n",
       "      <th>injured</th>\n",
       "      <th>killed</th>\n",
       "      <th>description</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>aspect</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slab_width</th>\n",
       "      <th>slab_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of four were snowmobiling in Sunshine ...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Ma</td>\n",
       "      <td>NE</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A party of two people were climbing the Skylad...</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Sa</td>\n",
       "      <td>N</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of two people were ski touring up the ...</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Sa</td>\n",
       "      <td>E</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>Eureka Peak</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A group of snowmobilers rode to the upper reac...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Sa</td>\n",
       "      <td>E</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>Reco Mountain</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A group of five snowmobilers was riding in Ant...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Ma</td>\n",
       "      <td>W</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                    location state/province  involved  injured  \\\n",
       "0  2021-11-27  Sunshine Bowl, Hasler Area             BC       3.0      0.0   \n",
       "1  2021-05-30   Mount Andromeda-Skyladder             AB       2.0      0.0   \n",
       "2  2021-04-05                  Haddo Peak             AB       2.0      0.0   \n",
       "3  2021-03-29                 Eureka Peak             BC       1.0      0.0   \n",
       "4  2021-03-04               Reco Mountain             BC       1.0      0.0   \n",
       "\n",
       "   killed                                        description  \\\n",
       "0       1  A party of four were snowmobiling in Sunshine ...   \n",
       "1       2  A party of two people were climbing the Skylad...   \n",
       "2       1  A party of two people were ski touring up the ...   \n",
       "3       1  A group of snowmobilers rode to the upper reac...   \n",
       "4       1  A group of five snowmobilers was riding in Ant...   \n",
       "\n",
       "            group_activity size  type trigger aspect  elevation  slab_width  \\\n",
       "0             Snowmobiling  3.0  Slab      Ma     NE     1700.0       350.0   \n",
       "1  Mountaineering/Climbing  2.5  Slab      Sa      N     3075.0        60.0   \n",
       "2      Skiing/Snowboarding  2.0  Slab      Sa      E     2950.0        40.0   \n",
       "3             Snowmobiling  2.5  Slab      Sa      E     2170.0        50.0   \n",
       "4             Snowmobiling  3.0  Slab      Ma      W     2465.0       125.0   \n",
       "\n",
       "   slab_thickness  \n",
       "0            60.0  \n",
       "1            75.0  \n",
       "2            50.0  \n",
       "3             NaN  \n",
       "4            85.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean up activity names\n",
    "skiing = ['Skiing', 'Skiing/Snowboarding', 'Snowboarding',\n",
    "           'Backcountry Skiing', 'Ski touring', 'Heliskiing',\n",
    "           'Mechanized Skiing', 'Out-of-bounds Skiing',\n",
    "           'Lift Skiing Closed', 'Lift Skiing Open', 'Out-of-Bounds Skiing', \n",
    "          'Off-piste skiing', 'Backcountry skiing', 'On skiruns', 'Ski', 'Snowboard']\n",
    "climbing = ['Mountaineering','Snow Biking','Snowshoeing',\n",
    "            'Foot','Ice Climbing', 'Snowshoeing & Hiking',\n",
    "            'Mountaineering/Climbing', 'Hiking on foot or snowshoeing']\n",
    "snowmobiling = ['Snowmobiling', 'Snowmobile']\n",
    "non_leisure = ['Work', 'At Outdoor Worksite', 'Control Work', 'Inside Building', 'Car/Truck on Road',\n",
    "               'Inside Car/Truck on Road', 'Outside Building', 'Travelling on road']\n",
    "other = ['Other Recreational', 'Hunting/Fishing', 'Sledding']\n",
    "\n",
    "def clean_group_activity(s):\n",
    "    \"\"\"\n",
    "    This function is used to clean the group_activity column.\n",
    "    It takes a string as input and if similar to any of the specified \n",
    "    group activities, assigns the output accordingly.\n",
    "    This way we have more general groups which are easier to interpret.\n",
    "    \"\"\"\n",
    "    if s in skiing:\n",
    "        return \"Skiing/Snowboarding\"\n",
    "    elif s in climbing:\n",
    "        return \"Mountaineering/Climbing\"\n",
    "    elif s in snowmobiling:\n",
    "        return \"Snowmobiling\"\n",
    "    elif s in non_leisure:\n",
    "        return \"Non-leisure Activities\"\n",
    "    elif s in other:\n",
    "        return \"Other Recreatinoal Activities\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "incidents['group_activity'] = incidents['group_activity'].apply(clean_group_activity)\n",
    "\n",
    "# Drop a duplicated coloumn\n",
    "cleaned_incidents = (pd.DataFrame(chain.from_iterable(incidents.avalanche_obs))\n",
    "                     .drop(columns=['observation_date'])\n",
    "                    )\n",
    "# Select only the columns with the variables of interest\n",
    "ca_incidents = (incidents\n",
    "                .iloc[:,[1,2,6,7,8,9,10,11,12]]\n",
    "                .merge(cleaned_incidents, left_index=True, right_index=True)\n",
    "               )\n",
    "\n",
    "# Clean up type column\n",
    "slab = ['S','CS','Slab', 'SS', 'HS', 'slab', 'layer', '2.5', 'facet', 'persistent']\n",
    "loose = ['Loose', 'L', '1.5']\n",
    "wet = ['WS', 'WL', 'water', 'slush', 'flow']\n",
    "other = ['I', 'C', 'R']\n",
    "\n",
    "def clean_type(s):\n",
    "    \"\"\"\n",
    "    This function is used to clean the type column.\n",
    "    It takes a string as input and if similar to any of the specified \n",
    "    type activities, assigns the output accordingly.\n",
    "    \"\"\"\n",
    "    if s in slab:\n",
    "        return \"Slab\"\n",
    "    elif s in loose:\n",
    "        return \"Loose\"\n",
    "    elif s in other:\n",
    "        return \"Other\" \n",
    "    elif s in wet:\n",
    "        return \"Wet\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "ca_incidents['type'] = ca_incidents['type'].apply(clean_type)\n",
    "ca_incidents = (ca_incidents\n",
    "                .drop(columns = ['location_elevation'])\n",
    "                .rename(columns={'ob_date': 'date',\n",
    "                                 'location_province': 'state/province',\n",
    "                                 'num_involved': 'involved',\n",
    "                                 'num_injured': 'injured',\n",
    "                                 'num_fatal': 'killed',\n",
    "                                 'comment': 'description'})\n",
    "               )\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(ca_incidents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43332e6e-6e66-48d8-8061-c9d6f63e0366",
   "metadata": {},
   "source": [
    "### Extracting Avalanche Data (United States) \n",
    "\n",
    "* Extract the avalanche data for the United States.\n",
    "* Use the package `BeautifulSoup` to help scrape and interact with html elements from any website.\n",
    "* It is discovered that all the useful tables are accessed through a url contained within an `iframe` in the source code.\n",
    "* Therefore, using `pd.read_html` helps us obtain all the tables.\n",
    "* Select the variables of interest and format the `Date` column by adding the year.\n",
    "* Finally, clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c71ae3b4-4524-4087-8dbc-41ec59fdfe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>ID</td>\n",
       "      <td>Ryan Peak, Idaho</td>\n",
       "      <td>1 skier and 1 snowmobiler killed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>WA</td>\n",
       "      <td>Silver Basin, closed portion of Crystal Mounta...</td>\n",
       "      <td>6 backcountry tourers caught and 1 killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>AK</td>\n",
       "      <td>Ruth Glacier, Denali National Park and Preserve</td>\n",
       "      <td>2 climbers caught in serac fall, 1 killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date State                                           Location  \\\n",
       "0   2021-12-17    ID                                   Ryan Peak, Idaho   \n",
       "1  2021-12-11     WA  Silver Basin, closed portion of Crystal Mounta...   \n",
       "2   2020-05-13    AK    Ruth Glacier, Denali National Park and Preserve   \n",
       "\n",
       "                                 Description  Killed  \n",
       "0           1 skier and 1 snowmobiler killed       2  \n",
       "1  6 backcountry tourers caught and 1 killed       1  \n",
       "2  2 climbers caught in serac fall, 1 killed       1  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = \"https://avalanche.org/avalanche-accidents/\"\n",
    "\n",
    "# This is done to prevent 'HTTPError: HTTP Error 403: Forbidden'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "\n",
    "# Prepare soup to access the source code\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "# Scrape the source code to access the source containing the tables\n",
    "soup.find('div', class_='content-area').iframe\n",
    "\n",
    "# Read the cleaned up source and convert it into dataframes \n",
    "df = pd.read_html('https://avalanche.state.co.us/caic/acc/acc_us.php', parse_dates=True)\n",
    "\n",
    "# Only select the useful tables\n",
    "df = df[1::2]\n",
    "\n",
    "# Clean the tables and merge them into one single dataframe representing cases in the US\n",
    "def format_date_col(s, year):\n",
    "    \"\"\"\n",
    "    This function is used to clean the date columns.\n",
    "    It takes a string and cleans the string by removing the dagger sign and\n",
    "    adds the year to the date string.\n",
    "    \"\"\"\n",
    "    month = s.replace('†','').replace('/','-')\n",
    "    year = str(year) + '-'\n",
    "    return year+month\n",
    "\n",
    "years = (2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009)\n",
    "for data, yr in zip(df, years):\n",
    "    data['Date'] = data['Date'].apply(format_date_col, args=[yr])\n",
    "    \n",
    "us_data = pd.concat(df).reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "us_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b32f6-ac40-4bdc-ac95-f1bbb9f379f7",
   "metadata": {},
   "source": [
    "* We discovered that there was further information contained in urls for each observation in the source code.\n",
    "* With the aid of the package `re`(regex), we acquire all the urls in a list form which helps us to scrape the data in order to add it to our DataFrame.\n",
    "* We also define a custom function called `getaccidentdetails()` to extract the tables contained in the url and parse them in to dictionary objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "60ac968b-a220-4376-bf5f-7a18bc8da708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls of details\n",
    "accidents = BeautifulSoup(urlopen('https://avalanche.state.co.us/caic/acc/acc_us.php').read(), \"html.parser\")\n",
    "reporturls = re.findall(\"win=window.open\\('(.*?)'\", accidents.prettify())\n",
    "# This is done as the url with index 50 has a different format preventing us from parsing it into a Table. \n",
    "del reporturls[50]\n",
    "\n",
    "def getaccidentdetails(url):\n",
    "    \"\"\"\n",
    "    This function accesses the individual url and parses the source code\n",
    "    into a dictionary.\n",
    "    \"\"\"\n",
    "    url = re.sub('&amp;', '&', url)\n",
    "    soup = BeautifulSoup(urlopen(url).read(), \"html.parser\")\n",
    "    details = dict()\n",
    "    for item in soup.find_all(\"li\", class_=\"acc_rep_list\"):\n",
    "        subi = item.find_all(\"li\")\n",
    "        if (len(subi) > 0):\n",
    "            for subitem in subi:\n",
    "                s = re.split(\":[\\xa0| ]\", subitem.text)\n",
    "                details[s[0]] = s[1]\n",
    "        else:\n",
    "            s = re.split(\":[\\xa0| ]\", item.text)\n",
    "            details[s[0]] = s[1]\n",
    "    return(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c86aa-4379-44e5-8657-7d5c21471d66",
   "metadata": {},
   "source": [
    "* We now use a comprehension to apply our function on each url in the list of urls.\n",
    "* `pd.DataFrame()` is then used to combine all of the individual dictionaries into a single DataFrame.\n",
    "* Since the following code is computationally intensive, we have showed the code as raw output. The output was saved as a .csv to make it more convenient in accessing our results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e88d82cd-e5e9-420d-adde-d68f3708a0b2",
   "metadata": {},
   "source": [
    "details = pd.DataFrame([getaccidentdetails(url) for url in reporturls[:]])\n",
    "details.to_csv('us_cases_extended.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f95714-6d2a-4ebd-a9ee-c36238b65462",
   "metadata": {},
   "source": [
    "#### Data Wrangling on Avalanche Data (US)\n",
    "\n",
    "* Begin by reading the .csv file with the extra information for each observation in the US data.\n",
    "* Next, replace missing values with 0 as we need to create a new column called `Involved` which represents all the individuals involved in the avalanche. This column is the sum of `Caught`, `Fully Buried`, `Injured`, `Killed`, `Partially Buried, Non-Critical` & `Partially Buried, Critical`.\n",
    "* Select only the columns of interest match the index of both the datasets and merge them together to create the `us_incidents` DataFrame.\n",
    "* Rename a few columns to match their names with that of the `ca_incidents` DataFrame.\n",
    "* Use `clean_group_activity()` to help make the column `group_activity` be similar to that of the `ca_incidents`' respective column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "914aeaef-8c27-4e90-bd2d-bd007a3a5b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>state/province</th>\n",
       "      <th>involved</th>\n",
       "      <th>injured</th>\n",
       "      <th>killed</th>\n",
       "      <th>description</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>aspect</th>\n",
       "      <th>elevation</th>\n",
       "      <th>sliding surface</th>\n",
       "      <th>slope angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Ryan Peak, Idaho</td>\n",
       "      <td>ID</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1 skier and 1 snowmobiler killed</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>Silver Basin, closed portion of Crystal Mounta...</td>\n",
       "      <td>WA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6 backcountry tourers caught and 1 killed</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Slab</td>\n",
       "      <td>AS - Skier</td>\n",
       "      <td>NE</td>\n",
       "      <td>6600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35 °</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>Ruth Glacier, Denali National Park and Preserve</td>\n",
       "      <td>AK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2 climbers caught in serac fall, 1 killed</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>N -  Natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>Matanuska Glacier</td>\n",
       "      <td>AK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1 heliskier killed</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>Lime Creek south of Edwards</td>\n",
       "      <td>CO</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2 sidecountry skiers caught, 1 buried and killed</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>2</td>\n",
       "      <td>Slab</td>\n",
       "      <td>AS - Skier</td>\n",
       "      <td>NW</td>\n",
       "      <td>9763</td>\n",
       "      <td>G - At Ground/Ice/Firm</td>\n",
       "      <td>45 °</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                           location  \\\n",
       "0   2021-12-17                                   Ryan Peak, Idaho   \n",
       "1  2021-12-11   Silver Basin, closed portion of Crystal Mounta...   \n",
       "2   2020-05-13    Ruth Glacier, Denali National Park and Preserve   \n",
       "3   2020-03-27                                  Matanuska Glacier   \n",
       "4   2020-03-22                        Lime Creek south of Edwards   \n",
       "\n",
       "  state/province  involved  injured  killed  \\\n",
       "0             ID       2.0        0       2   \n",
       "1             WA       4.0        0       1   \n",
       "2             AK       4.0        1       1   \n",
       "3             AK       1.0        0       1   \n",
       "4             CO       4.0        0       1   \n",
       "\n",
       "                                        description           group_activity  \\\n",
       "0                  1 skier and 1 snowmobiler killed             Snowmobiling   \n",
       "1         6 backcountry tourers caught and 1 killed      Skiing/Snowboarding   \n",
       "2         2 climbers caught in serac fall, 1 killed  Mountaineering/Climbing   \n",
       "3                                1 heliskier killed      Skiing/Snowboarding   \n",
       "4  2 sidecountry skiers caught, 1 buried and killed      Skiing/Snowboarding   \n",
       "\n",
       "  size     type       trigger aspect elevation         sliding surface  \\\n",
       "0  NaN  Unknown           NaN    NaN       NaN                     NaN   \n",
       "1  2.5     Slab    AS - Skier     NE     6600                      NaN   \n",
       "2  NaN    Other  N -  Natural    NaN       NaN                     NaN   \n",
       "3  NaN  Unknown           NaN    NaN       NaN                     NaN   \n",
       "4    2     Slab    AS - Skier     NW     9763   G - At Ground/Ice/Firm   \n",
       "\n",
       "  slope angle  \n",
       "0         NaN  \n",
       "1        35 °  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4        45 °  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Only select the columns of interest\n",
    "us_cases_extended = (pd.read_csv('us_cases_extended.csv')\n",
    "                     .fillna(0)\n",
    "                     .iloc[:,[6,8,9,10,11,12,13,14,15,18,19,20,21,22]]\n",
    "                     .assign(Involved = lambda x: x['Caught'] + x['Fully Buried'] \n",
    "                             + x['Injured'] + x['Killed'] + x['Partially Buried, Non-Critical']\n",
    "                             + x['Partially Buried, Critical'])\n",
    "                     .iloc[:,[0,5,7,8,9,10,11,12,13,14]]\n",
    "                    )\n",
    "# Merge the two dataframes into one\n",
    "us_incidents = (us_data\n",
    "                .drop(50)\n",
    "                .reset_index()\n",
    "                .drop(columns = ['index'])\n",
    "                .merge(us_cases_extended, left_index=True, right_index=True)\n",
    "                .rename(columns={'State': 'state/province',\n",
    "                                 'Slope Aspect': 'aspect',\n",
    "                                 'Site Elevation': 'elevation',\n",
    "                                 'Size - Destructive Force': 'size',\n",
    "                                 'Primary Travel Mode': 'group_activity'})\n",
    "                .iloc[:,[0,2,1,14,6,4,3,5,9,7,8,11,12,10,13]]\n",
    "                .replace('--', np.nan)\n",
    "               )\n",
    "us_incidents.columns = us_incidents.columns.str.lower()\n",
    "us_incidents['group_activity'] = us_incidents['group_activity'].apply(clean_group_activity)\n",
    "us_incidents['type'] = us_incidents['type'].apply(clean_type)\n",
    "us_incidents['size'] = [re.sub(\"D\", '', str(s)) if str(s)!='nan' else np.nan for s in us_incidents['size']]\n",
    "us_incidents['elevation'] = [re.sub(\"ft\", '', str(s)) if str(s)!='nan' else np.nan for s in us_incidents['elevation']]\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(us_incidents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f99a0-93d9-46de-87e1-8dc8c751ab8b",
   "metadata": {},
   "source": [
    "### Extracting Avalanche Data (Europe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "602b46ce-276d-4cc9-a73c-a3c00bf57100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>involved</th>\n",
       "      <th>killed</th>\n",
       "      <th>incident comment</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>Mentet</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Completely buried. Fatal result. Re-analisis ...</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "      <td>\"Destructive Avalanche Size of 2.5\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>Val d\\'Ayas, Gran Sommettaz</td>\n",
       "      <td>Italy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>La Thuille</td>\n",
       "      <td>Italy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>Monte Sorbetta</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>Großvenediger</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                     location  country  involved  killed  \\\n",
       "0  2021-11-28                       Mentet    Spain       1.0       1   \n",
       "1  2021-11-29  Val d\\'Ayas, Gran Sommettaz    Italy       NaN       1   \n",
       "2  2021-12-07                   La Thuille    Italy       3.0       1   \n",
       "3  2021-12-16               Monte Sorbetta    Italy       2.0       1   \n",
       "4  2020-10-10                Großvenediger  Austria       1.0       1   \n",
       "\n",
       "                                    incident comment           group_activity  \\\n",
       "0  \"Completely buried. Fatal result. Re-analisis ...  Mountaineering/Climbing   \n",
       "1                                                NaN      Skiing/Snowboarding   \n",
       "2                                                NaN      Skiing/Snowboarding   \n",
       "3                                                NaN      Skiing/Snowboarding   \n",
       "4                                                NaN  Mountaineering/Climbing   \n",
       "\n",
       "                           description  \n",
       "0  \"Destructive Avalanche Size of 2.5\"  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a list of urls to be read\n",
    "url1 = \"https://www.avalanches.org/fatalities/\"\n",
    "url2 = \"https://www.avalanches.org/fatalities/fatalities-20/\"\n",
    "url3 = \"https://www.avalanches.org/fatalities/fatalities-19/\"\n",
    "urls = [url1, url2, url3]\n",
    "\n",
    "# Scrape the tables from each url and make a list of the tables\n",
    "df = [pd.read_html(url, parse_dates=True) for url in urls]\n",
    "\n",
    "# Make a list of the dataframes within the table list and concat them together to form a single dataframe\n",
    "df = [df[0][0], df[1][0], df[2][0]]\n",
    "eu_incidents = (pd.concat(df)\n",
    "                .iloc[:,[3,1,2,8,7,10,11,9]]\n",
    "                .rename(columns={'Group Size': 'involved',\n",
    "                                 'Dead': 'killed',\n",
    "                                 'Avalanche Comment': 'description',\n",
    "                                 'Type': 'group_activity'})\n",
    "                .reset_index()\n",
    "                .drop(columns = ['index'])\n",
    "               )\n",
    "eu_incidents.columns = eu_incidents.columns.str.lower()\n",
    "eu_incidents['date'] = pd.to_datetime(eu_incidents['date']).dt.date\n",
    "eu_incidents['group_activity'] = eu_incidents['group_activity'].apply(clean_group_activity)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(eu_incidents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3a5da-988a-4a41-b486-2c573daee9ba",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15059d-31ce-4b76-8c92-18d0a3f49654",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "* All three datasets are merged together to form a single dataframe called `accidents` with all the similar columns.\n",
    "* The `Date` column is split into 3 columns: Year, Month and Day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "843f0a5e-6ac7-47be-bd78-0436a67cf72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>state/province</th>\n",
       "      <th>involved</th>\n",
       "      <th>killed</th>\n",
       "      <th>description</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of four were snowmobiling in Sunshine ...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A party of two people were climbing the Skylad...</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2021</td>\n",
       "      <td>05</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of two people were ski touring up the ...</td>\n",
       "      <td>Skiing/Snowboarding</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2021</td>\n",
       "      <td>04</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>Eureka Peak</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A group of snowmobilers rode to the upper reac...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2021</td>\n",
       "      <td>03</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>Reco Mountain</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A group of five snowmobilers was riding in Ant...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2021</td>\n",
       "      <td>03</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                    location state/province  involved  killed  \\\n",
       "0  2021-11-27  Sunshine Bowl, Hasler Area             BC       3.0       1   \n",
       "1  2021-05-30   Mount Andromeda-Skyladder             AB       2.0       2   \n",
       "2  2021-04-05                  Haddo Peak             AB       2.0       1   \n",
       "3  2021-03-29                 Eureka Peak             BC       1.0       1   \n",
       "4  2021-03-04               Reco Mountain             BC       1.0       1   \n",
       "\n",
       "                                         description           group_activity  \\\n",
       "0  A party of four were snowmobiling in Sunshine ...             Snowmobiling   \n",
       "1  A party of two people were climbing the Skylad...  Mountaineering/Climbing   \n",
       "2  A party of two people were ski touring up the ...      Skiing/Snowboarding   \n",
       "3  A group of snowmobilers rode to the upper reac...             Snowmobiling   \n",
       "4  A group of five snowmobilers was riding in Ant...             Snowmobiling   \n",
       "\n",
       "   type country  year month day  \n",
       "0  Slab  Canada  2021    11  27  \n",
       "1  Slab  Canada  2021    05  30  \n",
       "2  Slab  Canada  2021    04  05  \n",
       "3  Slab  Canada  2021    03  29  \n",
       "4  Slab  Canada  2021    03  04  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = (ca_incidents\n",
    "       .copy()\n",
    "       .assign(country = np.repeat(\"Canada\", len(ca_incidents), axis=0))\n",
    "       .iloc[:,[0,1,2,3,5,6,7,9,15]]\n",
    "      )\n",
    "df2 = (us_incidents\n",
    "       .copy()\n",
    "       .assign(country = np.repeat(\"United States\", len(us_incidents), axis=0))\n",
    "       .iloc[:,[0,1,2,3,5,6,7,9,15]]\n",
    "      )\n",
    "df3 = (eu_incidents\n",
    "       .copy()\n",
    "       .drop(columns = ['incident comment'])\n",
    "      )\n",
    "accidents = (pd.concat([df1, df2, df3])\n",
    "        .reset_index()\n",
    "        .drop(columns = ['index'])\n",
    "       )\n",
    "\n",
    "accidents[[\"year\", \"month\", \"day\"]] = accidents[\"date\"].str.split(\"-\", expand = True)\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e36ec-1e12-44aa-83ab-f02e158b1b93",
   "metadata": {},
   "source": [
    "### Number of Deaths per type of activity:\n",
    "\n",
    "Below is a plot of the total number of deaths caused by each type of activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8cfe6628-4192-4ece-9a9e-923927cd4d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>killed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_activity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mountaineering/Climbing</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-leisure Activities</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Recreatinoal Activities</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skiing/Snowboarding</th>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snowmobiling</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               killed\n",
       "group_activity                       \n",
       "Mountaineering/Climbing           191\n",
       "Non-leisure Activities            285\n",
       "Other Recreatinoal Activities      27\n",
       "Skiing/Snowboarding               531\n",
       "Snowmobiling                      235\n",
       "Unknown                           127"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.groupby(['group_activity'])['killed'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc69b4-c4ec-4aff-ab4b-c1c05d94ac57",
   "metadata": {},
   "source": [
    "### Plot of Number of Avalanches and number of deaths By date:\n",
    "\n",
    "The bar Plot depicted below shows the number of avalanches and the number of deaths caused by avalanches in each month (make bars broken up by type?)\n",
    "\n",
    "The purpose of this plot is to highlight whether avalanches tend to be more frequent at certain parts of the ski season than others. By including a line depicting deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed967a68-a236-4316-b57f-9839412f1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.groupby(['month'])['killed'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd144edd-7ba6-4140-b857-fafa0aa90b77",
   "metadata": {},
   "source": [
    "### Plot of Number of avalanches and number of deaths by date, broken up between types:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d4964-f46f-44d5-a6de-6a0cc1b6098b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74292182-2681-4f8d-977a-6d3b45d5d1c3",
   "metadata": {},
   "source": [
    "## Plan:\n",
    "\n",
    "- investigate frequency of accidents per type of activity \n",
    "    - try to use beautiful soup to rename values in the description for the US data if we can't get the avalanche details thing sorted in question 1\n",
    "    - use beautiful soup to rename values so that Type column in EU matches the activity column in Canada data\n",
    "    - create bar graph\n",
    "- investigate avalanche tendencies by date: See if there is a trend that there are more fatal avalanches later in the ski season than the start\n",
    "    - plot number of deaths as a function of the date, removing the year from the date\n",
    "\n",
    "- compare # of deaths or probability of fatal incident between activities or avalanche size. - will do depending on how data looks.\n",
    "    \n",
    "- prediction analysis:\n",
    "    - use a prediction technique (likely random forests, but will use the answer in question 2)\n",
    "    - as of now will only use avalanche Canada data unless we can scrape the data from US and EU to have the same variables but we are currently lost as to how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b63f51-b824-4009-b116-88caa742b363",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "2. You can run a prediction model with a smaller amount of data. Any method should be okay, but you will need to select less complex models (i.e. fewer features / bigger penalty for lasso, less deep trees). Cross-validation should do this automatically.\n",
    "<br>\n",
    "3. On the one hand, the prediction analysis would use the most ideas from the course. On the other hand, the other three bullets seem to be of more practical use. Both can lead to full marks. Do whatever you find more interesting. <br>\n",
    "I know this is a draft, but for the final version, be sure to add markdown cells between the code saying what you're doing and why.\n",
    "<br>\n",
    "4. I'm happy with anything that includes a url. If there is no url, be sure to have the author(s), title, journal (if applicable), and year.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd8421-f53a-4504-9505-10b1ba697251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
