{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d96d97-1623-467a-861b-633e9e47ba54",
   "metadata": {},
   "source": [
    "# Investigation of Avalanche Tendencies:\n",
    "## Authors: Lucas Crichton, Omer Tahir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7eefaf-0071-48d0-92b0-3aea0f8da554",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "## Introduction\n",
    "Within this investigation, data from North America and Europe was explored to reveal potential trends among avalanche occurrences. The data used was provided by Avalanche Canada,the Colorado Avalanche Information Center (CAIC) and European Avalanche Warning Services (EAWS). Firstly, an exploratory analysis will be conducted to investigate the relationship between the type of activity performed at the time of the avalanches and the number of deaths caused by the avalanches. Next We will investigate whether the number of avalanche deaths are relatively even throughout the ski season or whether there is a time of the year where deadly avalanches are more common. \n",
    "\n",
    "## Sources:\n",
    "- “Avalanche.org \" Accidents.” Avalanche.org, Colorado Avalanche Information Center, 5 Feb. 2020, https://avalanche.org/avalanche-accidents/. \n",
    "- “Fatalities.” EAWS, 25 Nov. 2021, https://www.avalanches.org/fatalities/fatalities-20/. \n",
    "- “Historical Incidents.” Avalanche Canada, https://www.avalanche.ca/incidents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6ceac-53bb-4bcb-9244-b407e0b89ca2",
   "metadata": {},
   "source": [
    "## Preparing the Data:\n",
    "firstly, we must prepare the data so that our data frame for our analysis contains data from all 3 sources and all necessary variables.\n",
    "\n",
    "## Installing Necessary Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f62b8b-e369-4ca9-98d2-52c0186a5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import warnings\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564970ec-8d5b-4bf0-8498-3f28efb63451",
   "metadata": {},
   "source": [
    "## Scraping Data off the web\n",
    "\n",
    "We will begin by scraping data for avalanche accidents across different regions such as Canada, the United States and Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfbfbc-40af-48bf-a5be-638a1035aba9",
   "metadata": {},
   "source": [
    "### Avalanche Data (Canada):\n",
    "\n",
    "* Below, we scrape the Canada avalanche data from the url.\n",
    "* With the help of the package `urllib`, we are able to extract the page source and decode it.\n",
    "* The result is a list of dictionary objects which are combined to form a single DataFrame.\n",
    "* The `id` column of the DataFrame gives access to further information for each observation. This information is extracted and added as columns to form a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e63caa3-c578-4059-a615-e950c3da1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ob_date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_desc</th>\n",
       "      <th>location_coords</th>\n",
       "      <th>location_coords_type</th>\n",
       "      <th>location_elevation</th>\n",
       "      <th>location_province</th>\n",
       "      <th>num_involved</th>\n",
       "      <th>num_injured</th>\n",
       "      <th>num_fatal</th>\n",
       "      <th>comment</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>avalanche_obs</th>\n",
       "      <th>weather_obs</th>\n",
       "      <th>weather_comment</th>\n",
       "      <th>snowpack_obs</th>\n",
       "      <th>snowpack_comment</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bc4720d-498c-4793-81ef-c43db9f36ca4</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>Approx. 17km East of Powder King ski area</td>\n",
       "      <td>[55.366223, -122.34096]</td>\n",
       "      <td>Lat/lng</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of four were snowmobiling in Sunshine ...</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>[{'size': '3.0', 'type': 'S', 'trigger': 'Ma',...</td>\n",
       "      <td>{'temp_present': None, 'temp_max': None, 'temp...</td>\n",
       "      <td>Overcast, windy conditions were reported with ...</td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td>A snow profile near the avalanche on the follo...</td>\n",
       "      <td>[{'date': '2021-11-30', 'title': 'Scene photo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3a4698-d047-4082-bdea-92f4db7e63bf</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>Approximately 96km SE of Jasper</td>\n",
       "      <td>[52.17836, -117.24785]</td>\n",
       "      <td>Lat/lng</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A party of two people were climbing the Skylad...</td>\n",
       "      <td>Mountaineering</td>\n",
       "      <td>[{'size': '2.5', 'type': 'S', 'trigger': 'Sa',...</td>\n",
       "      <td>{'temp_present': None, 'temp_max': 8.0, 'temp_...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-06-01', 'title': 'Mt Andromeda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba14a125-29f7-4432-97ad-73a53207a5e7</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>Approximately 6km SW of Lake Louise Village</td>\n",
       "      <td>[51.38329, -116.23453]</td>\n",
       "      <td>Lat/lng</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A party of two people were ski touring up the ...</td>\n",
       "      <td>Skiing</td>\n",
       "      <td>[{'size': '2.0', 'type': 'S', 'trigger': 'Sa',...</td>\n",
       "      <td>{'temp_present': None, 'temp_max': None, 'temp...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-04-05', 'title': 'Overview pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id     ob_date  \\\n",
       "0  8bc4720d-498c-4793-81ef-c43db9f36ca4  2021-11-27   \n",
       "1  6a3a4698-d047-4082-bdea-92f4db7e63bf  2021-05-30   \n",
       "2  ba14a125-29f7-4432-97ad-73a53207a5e7  2021-04-05   \n",
       "\n",
       "                     location                                location_desc  \\\n",
       "0  Sunshine Bowl, Hasler Area    Approx. 17km East of Powder King ski area   \n",
       "1   Mount Andromeda-Skyladder              Approximately 96km SE of Jasper   \n",
       "2                  Haddo Peak  Approximately 6km SW of Lake Louise Village   \n",
       "\n",
       "           location_coords location_coords_type  location_elevation  \\\n",
       "0  [55.366223, -122.34096]              Lat/lng              1700.0   \n",
       "1   [52.17836, -117.24785]              Lat/lng              3075.0   \n",
       "2   [51.38329, -116.23453]              Lat/lng              2950.0   \n",
       "\n",
       "  location_province  num_involved  num_injured  num_fatal  \\\n",
       "0                BC           3.0          0.0          1   \n",
       "1                AB           2.0          0.0          2   \n",
       "2                AB           2.0          0.0          1   \n",
       "\n",
       "                                             comment  group_activity  \\\n",
       "0  A party of four were snowmobiling in Sunshine ...    Snowmobiling   \n",
       "1  A party of two people were climbing the Skylad...  Mountaineering   \n",
       "2  A party of two people were ski touring up the ...          Skiing   \n",
       "\n",
       "                                       avalanche_obs  \\\n",
       "0  [{'size': '3.0', 'type': 'S', 'trigger': 'Ma',...   \n",
       "1  [{'size': '2.5', 'type': 'S', 'trigger': 'Sa',...   \n",
       "2  [{'size': '2.0', 'type': 'S', 'trigger': 'Sa',...   \n",
       "\n",
       "                                         weather_obs  \\\n",
       "0  {'temp_present': None, 'temp_max': None, 'temp...   \n",
       "1  {'temp_present': None, 'temp_max': 8.0, 'temp_...   \n",
       "2  {'temp_present': None, 'temp_max': None, 'temp...   \n",
       "\n",
       "                                     weather_comment  \\\n",
       "0  Overcast, windy conditions were reported with ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "\n",
       "                                        snowpack_obs  \\\n",
       "0  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "1  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "2  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "\n",
       "                                    snowpack_comment  \\\n",
       "0  A snow profile near the avalanche on the follo...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "\n",
       "                                           documents  \n",
       "0  [{'date': '2021-11-30', 'title': 'Scene photo'...  \n",
       "1  [{'date': '2021-06-01', 'title': 'Mt Andromeda...  \n",
       "2  [{'date': '2021-04-05', 'title': 'Overview pho...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Incidents\n",
    "url = \"http://incidents.avalanche.ca/public/incidents/?format=json\"\n",
    "req = urllib.request.Request(url)\n",
    "\n",
    "with urllib.request.urlopen(req) as response:\n",
    "    result = json.loads(response.read().decode('utf-8'))\n",
    "incident_list = result[\"results\"]\n",
    "\n",
    "while (result[\"next\"] != None):\n",
    "    req = urllib.request.Request(result[\"next\"])\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "    incident_list = incident_list + result[\"results\"]\n",
    "incidents_brief = pd.DataFrame.from_dict(incident_list,orient=\"columns\")\n",
    "\n",
    "# We can get more information about these incidents e.g. \"https://www.avalanche.ca/incidents/37d909e4-c6de-43f1-8416-57a34cd48255\"\n",
    "# this information is also available through the API\n",
    "def get_incident_details(id):\n",
    "    url = \"http://incidents.avalanche.ca/public/incidents/{}?format=json\".format(id)\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "    return(result)\n",
    "\n",
    "incidentsfile = \"https://datascience.quantecon.org/assets/data/avalanche_incidents.csv\"\n",
    "\n",
    "# To avoid loading the avalanche Canada servers, we save the incident details locally.\n",
    "if (not os.path.isfile(incidentsfile)):\n",
    "    incident_detail_list = incidents_brief.id.apply(get_incident_details).to_list()\n",
    "    incidents = pd.DataFrame.from_dict(incident_detail_list, orient=\"columns\")\n",
    "    incidents.to_csv(incidentsfile)\n",
    "else:\n",
    "    incidents = pd.read_csv(incidentsfile)\n",
    "    \n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(incidents.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2dacb-ed62-4a6f-ab18-43aab9740747",
   "metadata": {},
   "source": [
    "#### Data Wrangling on Avalanche Data (Canada)\n",
    "\n",
    "* We begin by renaming the categories in the `group_activity` column to increase interpretability.\n",
    "* Next, we extract one of the dataframes nested inside a column of the `incidents` dataframe.\n",
    "* We then concat the `group_activity` column to the `cleaned_incidents` dataframe.\n",
    "* Select only useful columns from the `incidents` dataframe and merge it with the `cleaned_incidents` dataframe to create the `ca_incidents` dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5607f588-c957-43d9-a66e-01995594b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ob_date</th>\n",
       "      <th>location_elevation</th>\n",
       "      <th>location_province</th>\n",
       "      <th>num_involved</th>\n",
       "      <th>num_injured</th>\n",
       "      <th>num_fatal</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>aspect</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slab_width</th>\n",
       "      <th>slab_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Ma</td>\n",
       "      <td>NE</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Sa</td>\n",
       "      <td>N</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Skiing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Sa</td>\n",
       "      <td>E</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Sa</td>\n",
       "      <td>E</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Slab</td>\n",
       "      <td>Ma</td>\n",
       "      <td>W</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ob_date  location_elevation location_province  num_involved  \\\n",
       "0  2021-11-27              1700.0                BC           3.0   \n",
       "1  2021-05-30              3075.0                AB           2.0   \n",
       "2  2021-04-05              2950.0                AB           2.0   \n",
       "3  2021-03-29              2170.0                BC           1.0   \n",
       "4  2021-03-04              2465.0                BC           1.0   \n",
       "\n",
       "   num_injured  num_fatal           group_activity size  type trigger aspect  \\\n",
       "0          0.0          1             Snowmobiling  3.0  Slab      Ma     NE   \n",
       "1          0.0          2  Mountaineering/Climbing  2.5  Slab      Sa      N   \n",
       "2          0.0          1                   Skiing  2.0  Slab      Sa      E   \n",
       "3          0.0          1             Snowmobiling  2.5  Slab      Sa      E   \n",
       "4          0.0          1             Snowmobiling  3.0  Slab      Ma      W   \n",
       "\n",
       "   elevation  slab_width  slab_thickness  \n",
       "0     1700.0       350.0            60.0  \n",
       "1     3075.0        60.0            75.0  \n",
       "2     2950.0        40.0            50.0  \n",
       "3     2170.0        50.0             NaN  \n",
       "4     2465.0       125.0            85.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean up activity names\n",
    "skiings = ['Skiing', 'Skiing/Snowboarding', 'Snowboarding',\n",
    "           'Backcountry Skiing', 'Ski touring', 'Heliskiing',\n",
    "           'Mechanized Skiing', 'Out-of-bounds Skiing',\n",
    "           'Lift Skiing Closed', 'Lift Skiing Open', 'Out-of-Bounds Skiing']\n",
    "mountaineering_and_climbing = ['Mountaineering',\n",
    "                               'Snow Biking',\n",
    "                               'Snowshoeing',\n",
    "                               'Ice Climbing',\n",
    "                               'Snowshoeing & Hiking']\n",
    "snowmobiling = ['Snowmobiling']\n",
    "non_leisure = ['Work', 'At Outdoor Worksite', 'Control Work',\n",
    "               'Inside Building', 'Car/Truck on Road',\n",
    "               'Inside Car/Truck on Road', 'Outside Building']\n",
    "other_or_unknown= ['Other Recreational', 'Hunting/Fishing', 'Unknown',]\n",
    "\n",
    "def clean_activity(s):\n",
    "    \"\"\"\n",
    "    This function is used to clean the group_activity column.\n",
    "    It takes a string as input and if similar to any of the specified \n",
    "    group activities, assigns the output accordingly.\n",
    "    This way we have more general groups which are easier to interpret.\n",
    "    \"\"\"\n",
    "    if s in skiings:\n",
    "        return \"Skiing\"\n",
    "    elif s in mountaineering_and_climbing:\n",
    "        return \"Mountaineering/Climbing\"\n",
    "    elif s in snowmobiling:\n",
    "        return \"Snowmobiling\"\n",
    "    elif s in non_leisure:\n",
    "        return \"Non-Leisure Activities\"\n",
    "    else:\n",
    "        return \"Other/Unknown\"\n",
    "\n",
    "incidents['group_activity'] = incidents['group_activity'].apply(clean_activity)\n",
    "\n",
    "# Drop a duplicated coloumn\n",
    "cleaned_incidents = (pd.DataFrame(chain.from_iterable(incidents.avalanche_obs))\n",
    "                     .drop(columns=['observation_date'])\n",
    "                    )\n",
    "# Select only the columns with the variables of interest\n",
    "ca_incidents = (incidents\n",
    "                .iloc[:,[1,6,7,8,9,10,12]]\n",
    "                .merge(cleaned_incidents, left_index=True, right_index=True)\n",
    "               )\n",
    "\n",
    "# Clean up type column\n",
    "slab = ['S','CS','Slab']\n",
    "unknown = ['U', 'Unkown', '']\n",
    "loose = ['Loose', 'L']\n",
    "\n",
    "def clean_type(s):\n",
    "    \"\"\"\n",
    "    This function is used to clean the type column.\n",
    "    It takes a string as input and if similar to any of the specified \n",
    "    type activities, assigns the output accordingly.\n",
    "    \"\"\"\n",
    "    if s in slab:\n",
    "        return \"Slab\"\n",
    "    elif s in unknown:\n",
    "        return \"Unknown\"\n",
    "    elif s in loose:\n",
    "        return \"Loose\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "ca_incidents['type'] = ca_incidents['type'].apply(clean_type)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(ca_incidents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43332e6e-6e66-48d8-8061-c9d6f63e0366",
   "metadata": {},
   "source": [
    "### Extracting Avalanche Data (United States) \n",
    "\n",
    "* We now extract the avalanche data for the United States.\n",
    "* We use the package `BeautifulSoup` which helps us to scrape and interact with html elements from any website.\n",
    "* It is discovered that all the useful tables are accessed through a url contained within an `iframe` in the source code.\n",
    "* Using `pd.read_html` we obtain all the tables and select those of interest.\n",
    "* The `Date` column is formatted by adding the year and the data is cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c71ae3b4-4524-4087-8dbc-41ec59fdfe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>ID</td>\n",
       "      <td>Ryan Peak, Idaho</td>\n",
       "      <td>1 skier and 1 snowmobiler killed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>WA</td>\n",
       "      <td>Silver Basin, closed portion of Crystal Mounta...</td>\n",
       "      <td>6 backcountry tourers caught and 1 killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>AK</td>\n",
       "      <td>Ruth Glacier, Denali National Park and Preserve</td>\n",
       "      <td>2 climbers caught in serac fall, 1 killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date State                                           Location  \\\n",
       "0   2021-12-17    ID                                   Ryan Peak, Idaho   \n",
       "1  2021-12-11     WA  Silver Basin, closed portion of Crystal Mounta...   \n",
       "2   2020-05-13    AK    Ruth Glacier, Denali National Park and Preserve   \n",
       "\n",
       "                                 Description  Killed  \n",
       "0           1 skier and 1 snowmobiler killed       2  \n",
       "1  6 backcountry tourers caught and 1 killed       1  \n",
       "2  2 climbers caught in serac fall, 1 killed       1  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "site = \"https://avalanche.org/avalanche-accidents/\"\n",
    "\n",
    "# This is done to prevent 'HTTPError: HTTP Error 403: Forbidden'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "\n",
    "# Prepare soup to access the source code\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "# Scrape the source code to access the source containing the tables\n",
    "soup.find('div', class_='content-area').iframe\n",
    "\n",
    "# Read the cleaned up source and convert it into dataframes \n",
    "df = pd.read_html('https://avalanche.state.co.us/caic/acc/acc_us.php', parse_dates=True)\n",
    "\n",
    "# Only select the useful tables\n",
    "df = df[1::2]\n",
    "\n",
    "# Clean the tables and merge them into one single dataframe representing cases in the US\n",
    "def format_date_col(s, year):\n",
    "    \"\"\"\n",
    "    This function is used to clean the date columns.\n",
    "    It takes a string and cleans the string by removing the dagger sign and\n",
    "    adds the year to the date string.\n",
    "    \"\"\"\n",
    "    month = s.replace('†','').replace('/','-')\n",
    "    year = str(year) + '-'\n",
    "    return year+month\n",
    "\n",
    "years = (2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009)\n",
    "for data, yr in zip(df, years):\n",
    "    data['Date'] = data['Date'].apply(format_date_col, args=[yr])\n",
    "    \n",
    "us_incidents = pd.concat(df).reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "us_incidents.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b32f6-ac40-4bdc-ac95-f1bbb9f379f7",
   "metadata": {},
   "source": [
    "* We discovered that there was further information contained in urls for each observation in the source code.\n",
    "* With the aid of the package `re`(regex), we acquire all the urls in a list form which helps us to scrape the data in order to add it to our DataFrame.\n",
    "* We also define a custom function called `getaccidentdetails()` to extract the tables contained in the url and parse them in to dictionary object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60ac968b-a220-4376-bf5f-7a18bc8da708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls of details\n",
    "import re\n",
    "accidents = BeautifulSoup(urlopen('https://avalanche.state.co.us/caic/acc/acc_us.php').read(), \"html.parser\")\n",
    "reporturls = re.findall(\"win=window.open\\('(.*?)'\", accidents.prettify())\n",
    "# This is done as the url with index 50 has a different format preventing us from parsing it into a Table. \n",
    "del reporturls[50]\n",
    "\n",
    "def getaccidentdetails(url):\n",
    "    \"\"\"\n",
    "    This function accesses the individual url and parses the source code\n",
    "    into a dictionary.\n",
    "    \"\"\"\n",
    "    url = re.sub('&amp;', '&', url)\n",
    "    soup = BeautifulSoup(urlopen(url).read(), \"html.parser\")\n",
    "    details = dict()\n",
    "    for item in soup.find_all(\"li\", class_=\"acc_rep_list\"):\n",
    "        subi = item.find_all(\"li\")\n",
    "        if (len(subi) > 0):\n",
    "            for subitem in subi:\n",
    "                s = re.split(\":[\\xa0| ]\", subitem.text)\n",
    "                details[s[0]] = s[1]\n",
    "        else:\n",
    "            s = re.split(\":[\\xa0| ]\", item.text)\n",
    "            details[s[0]] = s[1]\n",
    "    return(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c86aa-4379-44e5-8657-7d5c21471d66",
   "metadata": {},
   "source": [
    "* We now use a comprehension to apply our function on each url in the list of urls.\n",
    "* `pd.DataFrame()` is then used to combine all of the individual dictionaries into a single DataFrame.\n",
    "* Since the following code is computationally intensive, we have showed the code as raw output. In order to not run the code, we also saved the resulting DataFrame as a .csv for our convenience."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e88d82cd-e5e9-420d-adde-d68f3708a0b2",
   "metadata": {},
   "source": [
    "details = pd.DataFrame([getaccidentdetails(url) for url in reporturls[:]])\n",
    "details.to_csv('us_cases_extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "914aeaef-8c27-4e90-bd2d-bd007a3a5b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Location</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary Description</th>\n",
       "      <th>Primary Activity</th>\n",
       "      <th>Primary Travel Mode</th>\n",
       "      <th>Location Setting</th>\n",
       "      <th>Caught</th>\n",
       "      <th>Partially Buried, Non-Critical</th>\n",
       "      <th>Partially Buried, Critical</th>\n",
       "      <th>Fully Buried</th>\n",
       "      <th>Injured</th>\n",
       "      <th>Killed</th>\n",
       "      <th>Type</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>Trigger (subcode)</th>\n",
       "      <th>Size - Relative to Path</th>\n",
       "      <th>Size - Destructive Force</th>\n",
       "      <th>Sliding Surface</th>\n",
       "      <th>Slope Aspect</th>\n",
       "      <th>Site Elevation</th>\n",
       "      <th>Slope Angle</th>\n",
       "      <th>Slope Characteristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ryan Peak, Idaho</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>\\nUnknown\\n</td>\n",
       "      <td>1 skier and 1 snowmobiler killed</td>\n",
       "      <td>Hybrid Rider</td>\n",
       "      <td>Snowmobile</td>\n",
       "      <td>--</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Silver Basin, closed portion of Crystal Mounta...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 backcountry tourers caught and 1 killed</td>\n",
       "      <td>Backcountry Tourer</td>\n",
       "      <td>Ski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SS</td>\n",
       "      <td>AS - Skier</td>\n",
       "      <td>u - An unintentional release</td>\n",
       "      <td>R3</td>\n",
       "      <td>D2.5</td>\n",
       "      <td>--</td>\n",
       "      <td>NE</td>\n",
       "      <td>6600 ft</td>\n",
       "      <td>35 °</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Location       State  \\\n",
       "0           0                                   Ryan Peak, Idaho       Idaho   \n",
       "1           1  Silver Basin, closed portion of Crystal Mounta...  Washington   \n",
       "\n",
       "          Time                        Summary Description    Primary Activity  \\\n",
       "0  \\nUnknown\\n           1 skier and 1 snowmobiler killed        Hybrid Rider   \n",
       "1          NaN  6 backcountry tourers caught and 1 killed  Backcountry Tourer   \n",
       "\n",
       "  Primary Travel Mode Location Setting  Caught  \\\n",
       "0          Snowmobile               --       0   \n",
       "1                 Ski              NaN       0   \n",
       "\n",
       "   Partially Buried, Non-Critical  Partially Buried, Critical  Fully Buried  \\\n",
       "0                             0.0                         0.0             0   \n",
       "1                             NaN                         NaN             3   \n",
       "\n",
       "   Injured  Killed Type     Trigger             Trigger (subcode)  \\\n",
       "0        0       2   --          --                            --   \n",
       "1        0       1   SS  AS - Skier  u - An unintentional release   \n",
       "\n",
       "  Size - Relative to Path Size - Destructive Force Sliding Surface  \\\n",
       "0                      --                       --              --   \n",
       "1                      R3                     D2.5              --   \n",
       "\n",
       "  Slope Aspect Site Elevation Slope Angle Slope Characteristic  \n",
       "0           --             --          --                   --  \n",
       "1           NE        6600 ft        35 °                   --  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "us_cases_extended = pd.read_csv('us_cases_extended.csv')\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(us_cases_extended.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f99a0-93d9-46de-87e1-8dc8c751ab8b",
   "metadata": {},
   "source": [
    "### Extracting Avalanche Data (Europe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "602b46ce-276d-4cc9-a73c-a3c00bf57100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Avalanche Problem 1</th>\n",
       "      <th>Avalanche Problem 2</th>\n",
       "      <th>Forecasted Regional Danger Level</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Group Size</th>\n",
       "      <th>Avalanche Comment</th>\n",
       "      <th>Incident Comment</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2782</td>\n",
       "      <td>Mentet</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2021-11-28 00:00:00</td>\n",
       "      <td>Wind-drifted snow</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Destructive Avalanche Size of 2.5\"</td>\n",
       "      <td>\"Completely buried. Fatal result. Re-analisis ...</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2781</td>\n",
       "      <td>Val d\\'Ayas, Gran Sommettaz</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2021-11-29 12:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not rated at that time of the year</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-piste skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2783</td>\n",
       "      <td>La Thuille</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2021-12-07 13:09:00</td>\n",
       "      <td>Wind-drifted snow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Backcountry skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>Monte Sorbetta</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2021-12-16 13:04:00</td>\n",
       "      <td>Persistent weak layer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Backcountry skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1814</td>\n",
       "      <td>Großvenediger</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2020-10-10 00:00:00</td>\n",
       "      <td>Persistent weak layer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                     Location  Country                 Date  \\\n",
       "0  2782                       Mentet    Spain  2021-11-28 00:00:00   \n",
       "1  2781  Val d\\'Ayas, Gran Sommettaz    Italy  2021-11-29 12:05:00   \n",
       "2  2783                   La Thuille    Italy  2021-12-07 13:09:00   \n",
       "3  2785               Monte Sorbetta    Italy  2021-12-16 13:04:00   \n",
       "0  1814                Großvenediger  Austria  2020-10-10 00:00:00   \n",
       "\n",
       "     Avalanche Problem 1 Avalanche Problem 2  \\\n",
       "0      Wind-drifted snow                None   \n",
       "1                    NaN                 NaN   \n",
       "2      Wind-drifted snow                 NaN   \n",
       "3  Persistent weak layer                 NaN   \n",
       "0  Persistent weak layer                 NaN   \n",
       "\n",
       "     Forecasted Regional Danger Level  Dead  Group Size  \\\n",
       "0                                   3     1         1.0   \n",
       "1  Not rated at that time of the year     1         NaN   \n",
       "2                                   3     1         3.0   \n",
       "3                                   2     1         2.0   \n",
       "0                                 NaN     1         1.0   \n",
       "\n",
       "                     Avalanche Comment  \\\n",
       "0  \"Destructive Avalanche Size of 2.5\"   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "0                                  NaN   \n",
       "\n",
       "                                    Incident Comment                     Type  \n",
       "0  \"Completely buried. Fatal result. Re-analisis ...  Mountaineering/Climbing  \n",
       "1                                                NaN         Off-piste skiing  \n",
       "2                                                NaN       Backcountry skiing  \n",
       "3                                                NaN       Backcountry skiing  \n",
       "0                                                NaN  Mountaineering/Climbing  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a list of urls to be read\n",
    "url1 = \"https://www.avalanches.org/fatalities/\"\n",
    "url2 = \"https://www.avalanches.org/fatalities/fatalities-20/\"\n",
    "url3 = \"https://www.avalanches.org/fatalities/fatalities-19/\"\n",
    "urls = [url1, url2, url3]\n",
    "\n",
    "# Scrape the tables from each url and make a list of the tables\n",
    "df = [pd.read_html(url, parse_dates=True) for url in urls]\n",
    "\n",
    "# Make a list of the dataframes within the table list and concat them together to form a single dataframe\n",
    "df = [df[0][0], df[1][0], df[2][0]]\n",
    "eu_incidents = pd.concat(df)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "  display(eu_incidents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74292182-2681-4f8d-977a-6d3b45d5d1c3",
   "metadata": {},
   "source": [
    "## Plan:\n",
    "\n",
    "- investigate frequency of accidents per type of activity \n",
    "    - try to use beautiful soup to rename values in the description for the US data if we can't get the avalanche details thing sorted in question 1\n",
    "    - use beautiful soup to rename values so that Type column in EU matches the activity column in Canada data\n",
    "    - create bar graph\n",
    "- investigate avalanche tendencies by date: See if there is a trend that there are more fatal avalanches later in the ski season than the start\n",
    "    - plot number of deaths as a function of the date, removing the year from the date\n",
    "\n",
    "- compare # of deaths or probability of fatal incident between activities or avalanche size. - will do depending on how data looks.\n",
    "    \n",
    "- prediction analysis:\n",
    "    - use a prediction technique (likely random forests, but will use the answer in question 2)\n",
    "    - as of now will only use avalanche Canada data unless we can scrape the data from US and EU to have the same variables but we are currently lost as to how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b63f51-b824-4009-b116-88caa742b363",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "2. You can run a prediction model with a smaller amount of data. Any method should be okay, but you will need to select less complex models (i.e. fewer features / bigger penalty for lasso, less deep trees). Cross-validation should do this automatically.\n",
    "<br>\n",
    "3. On the one hand, the prediction analysis would use the most ideas from the course. On the other hand, the other three bullets seem to be of more practical use. Both can lead to full marks. Do whatever you find more interesting. <br>\n",
    "I know this is a draft, but for the final version, be sure to add markdown cells between the code saying what you're doing and why.\n",
    "<br>\n",
    "4. I'm happy with anything that includes a url. If there is no url, be sure to have the author(s), title, journal (if applicable), and year.\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
