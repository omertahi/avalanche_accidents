{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb41118-11a6-41be-8f5b-074a8e351642",
   "metadata": {},
   "source": [
    "# Investigation of Avalanche Tendencies:\n",
    "## Lucas Crichton, Omer Tahir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b618cf8-9ed0-4848-8b72-63dccd441fe9",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "## Introduction\n",
    "Within this investigation, data from North America and Europe was explored to reveal potential trends among avalanche occurrences. The data used was provided by Avalanche Canada,the Colorado Avalanche Information Center (CAIC) and European Avalanche Warning Services (EAWS). Firstly, an exploratory analysis will be conducted to investigate the relationship between the type of activity performed at the time of the avalanches and the number of deaths caused by the avalanches. Next We will investigate whether the number of avalanche deaths are relatively even throughout the ski season or whether there is a time of the year where deadly avalanches are more common. \n",
    "\n",
    "## Sources:\n",
    "- “Avalanche.org \" Accidents.” Avalanche.org, Colorado Avalanche Information Center, 5 Feb. 2020, https://avalanche.org/avalanche-accidents/. \n",
    "- “Fatalities.” EAWS, 25 Nov. 2021, https://www.avalanches.org/fatalities/fatalities-20/. \n",
    "- “Historical Incidents.” Avalanche Canada, https://www.avalanche.ca/incidents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c7439-9fb9-40be-892d-57842fca5fc6",
   "metadata": {},
   "source": [
    "# Preparing the Data:\n",
    "firstly, we must prepare the data so that our data frame for our analysis contains data from all 3 sources and all necessary variables.\n",
    "\n",
    "## Installing Necessary Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f88787-86e4-4ebe-a30b-cd64f07c66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbb286-4b87-4ec8-8c6f-7c07cab103b7",
   "metadata": {},
   "source": [
    "## Extracting Avalanche Canada Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d1e28f3-3dbc-494c-8a80-3cd6db1ff74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_province</th>\n",
       "      <th>group_activity</th>\n",
       "      <th>num_involved</th>\n",
       "      <th>num_injured</th>\n",
       "      <th>num_fatal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bc4720d-498c-4793-81ef-c43db9f36ca4</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>BC</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3a4698-d047-4082-bdea-92f4db7e63bf</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>AB</td>\n",
       "      <td>Mountaineering</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba14a125-29f7-4432-97ad-73a53207a5e7</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>AB</td>\n",
       "      <td>Skiing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59023c05-b679-4e9f-9c06-910021318663</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>Eureka Peak</td>\n",
       "      <td>BC</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10774b2d-b7de-42ac-a600-9828cb4e6129</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>Reco Mountain</td>\n",
       "      <td>BC</td>\n",
       "      <td>Snowmobiling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>101c517b-29a4-4c49-8934-f6c56ddd882d</td>\n",
       "      <td>1840-02-01</td>\n",
       "      <td>Château-Richer</td>\n",
       "      <td>QC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>b2e1c50a-1533-4145-a1a2-0befca0154d5</td>\n",
       "      <td>1836-02-09</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>QC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>18e8f963-da33-4682-9312-57ca2cc9ad8d</td>\n",
       "      <td>1833-05-24</td>\n",
       "      <td>Carbonear</td>\n",
       "      <td>NL</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>083d22df-ed50-4687-b9ab-1649960a0fbe</td>\n",
       "      <td>1825-02-04</td>\n",
       "      <td>Saint-Joseph de Lévis</td>\n",
       "      <td>QC</td>\n",
       "      <td>Inside Building</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>f498c48a-981d-43cf-ac16-151b8794435c</td>\n",
       "      <td>1782-01-01</td>\n",
       "      <td>Nain</td>\n",
       "      <td>NL</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id        date  \\\n",
       "0    8bc4720d-498c-4793-81ef-c43db9f36ca4  2021-11-27   \n",
       "1    6a3a4698-d047-4082-bdea-92f4db7e63bf  2021-05-30   \n",
       "2    ba14a125-29f7-4432-97ad-73a53207a5e7  2021-04-05   \n",
       "3    59023c05-b679-4e9f-9c06-910021318663  2021-03-29   \n",
       "4    10774b2d-b7de-42ac-a600-9828cb4e6129  2021-03-04   \n",
       "..                                    ...         ...   \n",
       "484  101c517b-29a4-4c49-8934-f6c56ddd882d  1840-02-01   \n",
       "485  b2e1c50a-1533-4145-a1a2-0befca0154d5  1836-02-09   \n",
       "486  18e8f963-da33-4682-9312-57ca2cc9ad8d  1833-05-24   \n",
       "487  083d22df-ed50-4687-b9ab-1649960a0fbe  1825-02-04   \n",
       "488  f498c48a-981d-43cf-ac16-151b8794435c  1782-01-01   \n",
       "\n",
       "                       location location_province   group_activity  \\\n",
       "0    Sunshine Bowl, Hasler Area                BC     Snowmobiling   \n",
       "1     Mount Andromeda-Skyladder                AB   Mountaineering   \n",
       "2                    Haddo Peak                AB           Skiing   \n",
       "3                   Eureka Peak                BC     Snowmobiling   \n",
       "4                 Reco Mountain                BC     Snowmobiling   \n",
       "..                          ...               ...              ...   \n",
       "484              Château-Richer                QC          Unknown   \n",
       "485                      Quebec                QC          Unknown   \n",
       "486                   Carbonear                NL          Unknown   \n",
       "487       Saint-Joseph de Lévis                QC  Inside Building   \n",
       "488                        Nain                NL          Unknown   \n",
       "\n",
       "     num_involved  num_injured  num_fatal  \n",
       "0             3.0          0.0          1  \n",
       "1             2.0          0.0          2  \n",
       "2             2.0          0.0          1  \n",
       "3             1.0          0.0          1  \n",
       "4             1.0          0.0          1  \n",
       "..            ...          ...        ...  \n",
       "484           NaN          NaN          1  \n",
       "485           NaN          NaN          1  \n",
       "486           NaN          0.0          1  \n",
       "487           NaN          NaN          5  \n",
       "488           NaN          NaN         22  \n",
       "\n",
       "[489 rows x 8 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data on avalanche forecasts and incidents from Avalanche Canada\n",
    "# Avalanche Canada has an unstable public api\n",
    "# https://github.com/avalanche-canada/ac-web\n",
    "# Since API might change, this code might break\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Incidents\n",
    "url = \"http://incidents.avalanche.ca/public/incidents/?format=json\"\n",
    "req = urllib.request.Request(url)\n",
    "with urllib.request.urlopen(req) as response:\n",
    "    result = json.loads(response.read().decode('utf-8'))\n",
    "incident_list = result[\"results\"]\n",
    "# incident_list\n",
    "\n",
    "while (result[\"next\"] != None):\n",
    "    req = urllib.request.Request(result[\"next\"])\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "    incident_list = incident_list + result[\"results\"]\n",
    "incident_list\n",
    "\n",
    "incidents_brief = pd.DataFrame.from_dict(incident_list,orient=\"columns\")\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 8\n",
    "incidents_brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbc395a2-ede2-4313-8fb4-0175c64f0674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this video, we use two of Python 3's standard library modules, re and urllib, to parse paragraph data from a website. As we saw, initially, when you use Python 3 and urllib to parse a website, you get all of the HTML data, like using \"view source\" on a web page. This HTML data is great if you are viewing via a browser, but is incredibly messy if you are viewing the raw source. For this reason, we need to build something that can sift through the mess and just pull the article data that we are interested in. There are some web scraping libraries out there, namely BeautifulSoup, which are aimed at doing this same sort of task.\n",
      "On to the code:\n",
      "Up to this point, everything should look pretty typical, as you've seen it all before. We specify our url, our values dict, encode the values, build our request, make our request, and then store the request to respData. We can print it out if we want to see what we're working with. If you are using an IDE, sometimes printing out the source code is not the greatest idea. Many webpages, especially larger ones, have very large amounts of code in their source. Printing all of this out can take quite a while in the IDLE. Personally, I prefer to just view-source. In Google Chrome, for example, control+u will view-source. \n",
      "Alternatively, you should be able to just right-click on the page and select view-source. Once there, you want to look for your \"target data.\" In our case, we just want to take the paragraph text data. If you're looking for something specific, then what I suggest you do is copy some of the \"thing\" you are looking for. So in the case of specific paragraph text, highlight some of it, copy it, then view the source. Once there, do a find operation, control+f usually will open one up, then paste in what you are looking for. Once you've done that, you should be able to find some identifiers near what you are looking for. In the case of paragraph data, it is paragraph data because people tell the browser it is. This means usually that there are literally paragraph tags around what we want that look like: \n",
      "Some websites get fancy with their HTML and do things like \n",
      "...keep this in mind. With that in mind, most websites just use simple paragraph tags, so let's show that: \n",
      "The above regular expression states: Find me anything that starts with a paragraph tag, then in our parenthesis, we say exactly \"what\" we're looking for, and that's basically any character, except for a newline, one or more repetitions of that character, and finally there may be 0 or 1 of THIS expression. After that, we have a closing paragraph tag. We find as many of these that exist. This will generate a list, which we can then iterate through with:\n",
      "The output should be a bunch of paragraph data from our website.\n",
      "The next tutorial: <a title=\"Tkinter intro\" href=\"/python-3-tkinter-basics-tutorial/?completed=/parse-website-using-regular-expressions-urllib/\"><button class=\"btn\" style=\"background-color:#FFD166; color:#000000\">Tkinter intro</button></a>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "url = 'http://pythonprogramming.net/parse-website-using-regular-expressions-urllib/'\n",
    "\n",
    "req = urllib.request.Request(url)\n",
    "resp = urllib.request.urlopen(req)\n",
    "respData = resp.read().decode('utf-8')\n",
    "print(respData)\n",
    "paragraphs = re.findall(r'<p>(.*?)</p>',str(respData))\n",
    "\n",
    "for eachP in paragraphs:\n",
    "    print(eachP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e63caa3-c578-4059-a615-e950c3da1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ob_date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_desc</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_comment</th>\n",
       "      <th>snowpack_obs</th>\n",
       "      <th>snowpack_comment</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bc4720d-498c-4793-81ef-c43db9f36ca4</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>Approx. 17km East of Powder King ski area</td>\n",
       "      <td>...</td>\n",
       "      <td>Overcast, windy conditions were reported with ...</td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td>A snow profile near the avalanche on the follo...</td>\n",
       "      <td>[{'date': '2021-11-30', 'title': 'Scene photo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3a4698-d047-4082-bdea-92f4db7e63bf</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>Approximately 96km SE of Jasper</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-06-01', 'title': 'Mt Andromeda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba14a125-29f7-4432-97ad-73a53207a5e7</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>Approximately 6km SW of Lake Louise Village</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-04-05', 'title': 'Overview pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59023c05-b679-4e9f-9c06-910021318663</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>Eureka Peak</td>\n",
       "      <td>Approximately 100km east of Williams Lake</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-04-01', 'title': 'Overview', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10774b2d-b7de-42ac-a600-9828cb4e6129</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>Reco Mountain</td>\n",
       "      <td>Approximately 13km east of New Denver</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-03-05', 'title': 'Scene Overvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>101c517b-29a4-4c49-8934-f6c56ddd882d</td>\n",
       "      <td>1840-02-01</td>\n",
       "      <td>Château-Richer</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>b2e1c50a-1533-4145-a1a2-0befca0154d5</td>\n",
       "      <td>1836-02-09</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>more details unknown</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>18e8f963-da33-4682-9312-57ca2cc9ad8d</td>\n",
       "      <td>1833-05-24</td>\n",
       "      <td>Carbonear</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'title': 'Carbonear, May 24, 1833', 'source'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>083d22df-ed50-4687-b9ab-1649960a0fbe</td>\n",
       "      <td>1825-02-04</td>\n",
       "      <td>Saint-Joseph de Lévis</td>\n",
       "      <td>Pointe Lévis</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>f498c48a-981d-43cf-ac16-151b8794435c</td>\n",
       "      <td>1782-01-01</td>\n",
       "      <td>Nain</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'title': 'Nain, 1781-2', 'source': 'NFLD Geo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id     ob_date  \\\n",
       "0    8bc4720d-498c-4793-81ef-c43db9f36ca4  2021-11-27   \n",
       "1    6a3a4698-d047-4082-bdea-92f4db7e63bf  2021-05-30   \n",
       "2    ba14a125-29f7-4432-97ad-73a53207a5e7  2021-04-05   \n",
       "3    59023c05-b679-4e9f-9c06-910021318663  2021-03-29   \n",
       "4    10774b2d-b7de-42ac-a600-9828cb4e6129  2021-03-04   \n",
       "..                                    ...         ...   \n",
       "484  101c517b-29a4-4c49-8934-f6c56ddd882d  1840-02-01   \n",
       "485  b2e1c50a-1533-4145-a1a2-0befca0154d5  1836-02-09   \n",
       "486  18e8f963-da33-4682-9312-57ca2cc9ad8d  1833-05-24   \n",
       "487  083d22df-ed50-4687-b9ab-1649960a0fbe  1825-02-04   \n",
       "488  f498c48a-981d-43cf-ac16-151b8794435c  1782-01-01   \n",
       "\n",
       "                       location                                location_desc  \\\n",
       "0    Sunshine Bowl, Hasler Area    Approx. 17km East of Powder King ski area   \n",
       "1     Mount Andromeda-Skyladder              Approximately 96km SE of Jasper   \n",
       "2                    Haddo Peak  Approximately 6km SW of Lake Louise Village   \n",
       "3                   Eureka Peak    Approximately 100km east of Williams Lake   \n",
       "4                 Reco Mountain        Approximately 13km east of New Denver   \n",
       "..                          ...                                          ...   \n",
       "484              Château-Richer                                                \n",
       "485                      Quebec                         more details unknown   \n",
       "486                   Carbonear                                                \n",
       "487       Saint-Joseph de Lévis                                 Pointe Lévis   \n",
       "488                        Nain                                                \n",
       "\n",
       "     ...                                    weather_comment  \\\n",
       "0    ...  Overcast, windy conditions were reported with ...   \n",
       "1    ...                                                      \n",
       "2    ...                                                      \n",
       "3    ...                                                      \n",
       "4    ...                                                      \n",
       "..   ...                                                ...   \n",
       "484  ...                                                      \n",
       "485  ...                                                      \n",
       "486  ...                                                      \n",
       "487  ...                                                      \n",
       "488  ...                                                      \n",
       "\n",
       "                                          snowpack_obs  \\\n",
       "0    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "1    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "2    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "3    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "4    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "..                                                 ...   \n",
       "484  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "485  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "486  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "487  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "488  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "\n",
       "                                      snowpack_comment  \\\n",
       "0    A snow profile near the avalanche on the follo...   \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "484                                                      \n",
       "485                                                      \n",
       "486                                                      \n",
       "487                                                      \n",
       "488                                                      \n",
       "\n",
       "                                             documents  \n",
       "0    [{'date': '2021-11-30', 'title': 'Scene photo'...  \n",
       "1    [{'date': '2021-06-01', 'title': 'Mt Andromeda...  \n",
       "2    [{'date': '2021-04-05', 'title': 'Overview pho...  \n",
       "3    [{'date': '2021-04-01', 'title': 'Overview', '...  \n",
       "4    [{'date': '2021-03-05', 'title': 'Scene Overvi...  \n",
       "..                                                 ...  \n",
       "484                                                 []  \n",
       "485                                                 []  \n",
       "486  [{'title': 'Carbonear, May 24, 1833', 'source'...  \n",
       "487                                                 []  \n",
       "488  [{'title': 'Nain, 1781-2', 'source': 'NFLD Geo...  \n",
       "\n",
       "[489 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incidents\n",
    "# We can get more information about these incidents e.g. \"https://www.avalanche.ca/incidents/37d909e4-c6de-43f1-8416-57a34cd48255\"\n",
    "# this information is also available through the API\n",
    "def get_incident_details(id):\n",
    "    url = \"http://incidents.avalanche.ca/public/incidents/{}?format=json\".format(id)\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "    return(result)\n",
    "\n",
    "\n",
    "incidentsfile = \"https://datascience.quantecon.org/assets/data/avalanche_incidents.csv\"\n",
    "\n",
    "# To avoid loading the avalanche Canada servers, we save the incident details locally.\n",
    "if (not os.path.isfile(incidentsfile)):\n",
    "    incident_detail_list = incidents_brief.id.apply(get_incident_details).to_list()\n",
    "    incidents = pd.DataFrame.from_dict(incident_detail_list, orient=\"columns\")\n",
    "    incidents.to_csv(incidentsfile)\n",
    "else:\n",
    "    incidents = pd.read_csv(incidentsfile)\n",
    "\n",
    "incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5607f588-c957-43d9-a66e-01995594b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ob_date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_desc</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_comment</th>\n",
       "      <th>snowpack_obs</th>\n",
       "      <th>snowpack_comment</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bc4720d-498c-4793-81ef-c43db9f36ca4</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>Sunshine Bowl, Hasler Area</td>\n",
       "      <td>Approx. 17km East of Powder King ski area</td>\n",
       "      <td>...</td>\n",
       "      <td>Overcast, windy conditions were reported with ...</td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td>A snow profile near the avalanche on the follo...</td>\n",
       "      <td>[{'date': '2021-11-30', 'title': 'Scene photo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3a4698-d047-4082-bdea-92f4db7e63bf</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>Mount Andromeda-Skyladder</td>\n",
       "      <td>Approximately 96km SE of Jasper</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-06-01', 'title': 'Mt Andromeda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba14a125-29f7-4432-97ad-73a53207a5e7</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Haddo Peak</td>\n",
       "      <td>Approximately 6km SW of Lake Louise Village</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-04-05', 'title': 'Overview pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59023c05-b679-4e9f-9c06-910021318663</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>Eureka Peak</td>\n",
       "      <td>Approximately 100km east of Williams Lake</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-04-01', 'title': 'Overview', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10774b2d-b7de-42ac-a600-9828cb4e6129</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>Reco Mountain</td>\n",
       "      <td>Approximately 13km east of New Denver</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'date': '2021-03-05', 'title': 'Scene Overvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>101c517b-29a4-4c49-8934-f6c56ddd882d</td>\n",
       "      <td>1840-02-01</td>\n",
       "      <td>Château-Richer</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>b2e1c50a-1533-4145-a1a2-0befca0154d5</td>\n",
       "      <td>1836-02-09</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>more details unknown</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>18e8f963-da33-4682-9312-57ca2cc9ad8d</td>\n",
       "      <td>1833-05-24</td>\n",
       "      <td>Carbonear</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'title': 'Carbonear, May 24, 1833', 'source'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>083d22df-ed50-4687-b9ab-1649960a0fbe</td>\n",
       "      <td>1825-02-04</td>\n",
       "      <td>Saint-Joseph de Lévis</td>\n",
       "      <td>Pointe Lévis</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>f498c48a-981d-43cf-ac16-151b8794435c</td>\n",
       "      <td>1782-01-01</td>\n",
       "      <td>Nain</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>{'hs': None, 'hn24': None, 'hst': None, 'hst_r...</td>\n",
       "      <td></td>\n",
       "      <td>[{'title': 'Nain, 1781-2', 'source': 'NFLD Geo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id     ob_date  \\\n",
       "0    8bc4720d-498c-4793-81ef-c43db9f36ca4  2021-11-27   \n",
       "1    6a3a4698-d047-4082-bdea-92f4db7e63bf  2021-05-30   \n",
       "2    ba14a125-29f7-4432-97ad-73a53207a5e7  2021-04-05   \n",
       "3    59023c05-b679-4e9f-9c06-910021318663  2021-03-29   \n",
       "4    10774b2d-b7de-42ac-a600-9828cb4e6129  2021-03-04   \n",
       "..                                    ...         ...   \n",
       "484  101c517b-29a4-4c49-8934-f6c56ddd882d  1840-02-01   \n",
       "485  b2e1c50a-1533-4145-a1a2-0befca0154d5  1836-02-09   \n",
       "486  18e8f963-da33-4682-9312-57ca2cc9ad8d  1833-05-24   \n",
       "487  083d22df-ed50-4687-b9ab-1649960a0fbe  1825-02-04   \n",
       "488  f498c48a-981d-43cf-ac16-151b8794435c  1782-01-01   \n",
       "\n",
       "                       location                                location_desc  \\\n",
       "0    Sunshine Bowl, Hasler Area    Approx. 17km East of Powder King ski area   \n",
       "1     Mount Andromeda-Skyladder              Approximately 96km SE of Jasper   \n",
       "2                    Haddo Peak  Approximately 6km SW of Lake Louise Village   \n",
       "3                   Eureka Peak    Approximately 100km east of Williams Lake   \n",
       "4                 Reco Mountain        Approximately 13km east of New Denver   \n",
       "..                          ...                                          ...   \n",
       "484              Château-Richer                                                \n",
       "485                      Quebec                         more details unknown   \n",
       "486                   Carbonear                                                \n",
       "487       Saint-Joseph de Lévis                                 Pointe Lévis   \n",
       "488                        Nain                                                \n",
       "\n",
       "     ...                                    weather_comment  \\\n",
       "0    ...  Overcast, windy conditions were reported with ...   \n",
       "1    ...                                                      \n",
       "2    ...                                                      \n",
       "3    ...                                                      \n",
       "4    ...                                                      \n",
       "..   ...                                                ...   \n",
       "484  ...                                                      \n",
       "485  ...                                                      \n",
       "486  ...                                                      \n",
       "487  ...                                                      \n",
       "488  ...                                                      \n",
       "\n",
       "                                          snowpack_obs  \\\n",
       "0    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "1    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "2    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "3    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "4    {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "..                                                 ...   \n",
       "484  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "485  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "486  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "487  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "488  {'hs': None, 'hn24': None, 'hst': None, 'hst_r...   \n",
       "\n",
       "                                      snowpack_comment  \\\n",
       "0    A snow profile near the avalanche on the follo...   \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "484                                                      \n",
       "485                                                      \n",
       "486                                                      \n",
       "487                                                      \n",
       "488                                                      \n",
       "\n",
       "                                             documents  \n",
       "0    [{'date': '2021-11-30', 'title': 'Scene photo'...  \n",
       "1    [{'date': '2021-06-01', 'title': 'Mt Andromeda...  \n",
       "2    [{'date': '2021-04-05', 'title': 'Overview pho...  \n",
       "3    [{'date': '2021-04-01', 'title': 'Overview', '...  \n",
       "4    [{'date': '2021-03-05', 'title': 'Scene Overvi...  \n",
       "..                                                 ...  \n",
       "484                                                 []  \n",
       "485                                                 []  \n",
       "486  [{'title': 'Carbonear, May 24, 1833', 'source'...  \n",
       "487                                                 []  \n",
       "488  [{'title': 'Nain, 1781-2', 'source': 'NFLD Geo...  \n",
       "\n",
       "[489 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# clean up activity names\n",
    "incidents.group_activity.unique()\n",
    "\n",
    "skiings = [ 'Skiing', 'Skiing/Snowboarding',\n",
    "      'Snowboarding', 'Backcountry Skiing',\n",
    "        'Ski touring', 'Heliskiing',\n",
    "       'Mechanized Skiing', 'Out-of-bounds Skiing', 'Lift Skiing Closed', 'Lift Skiing Open',\n",
    "       'Out-of-Bounds Skiing']\n",
    "mountaineering_and_climbing = ['Mountaineering',\n",
    "       'Snow Biking', 'Snowshoeing', \n",
    "       'Ice Climbing',\n",
    "       'Snowshoeing & Hiking']\n",
    "snowmobiling = ['Snowmobiling']\n",
    "non_leisure = [ 'Work',\n",
    "       'At Outdoor Worksite',\n",
    "         'Control Work',\n",
    "       'Inside Building', 'Car/Truck on Road', 'Inside Car/Truck on Road', 'Outside Building']\n",
    "other_or_unknown= ['Other Recreational', 'Hunting/Fishing', 'Unknown',]\n",
    "def activities_can(s):\n",
    "    if s in skiings:\n",
    "        return \"Skiing\"\n",
    "    elif s in mountaineering_and_climbing:\n",
    "        return \"Mountaineering/Climbing\"\n",
    "    elif s in snowmobiling:\n",
    "        return \"Snowmobiling\"\n",
    "    elif s in non_leisure:\n",
    "        return \"Non-Leisure Activities\"\n",
    "    else:\n",
    "        return \"Other/Unknown\"\n",
    "\n",
    "incidents['group_activity'] = incidents['group_activity'].apply(activities_can)\n",
    "incidents['group_activity'].unique()\n",
    "\n",
    "\n",
    "incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecf57ab-b7ab-4b12-b44a-bafe576de86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>aspect</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slab_width</th>\n",
       "      <th>slab_thickness</th>\n",
       "      <th>observation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Ma</td>\n",
       "      <td>NE</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>S</td>\n",
       "      <td>Sa</td>\n",
       "      <td>N</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Sa</td>\n",
       "      <td>E</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>CS</td>\n",
       "      <td>Sa</td>\n",
       "      <td>E</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Ma</td>\n",
       "      <td>W</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>U</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>U</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1843-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>U</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1840-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>U</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1836-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Na</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1825-02-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    size type trigger aspect  elevation  slab_width  slab_thickness  \\\n",
       "0    3.0    S      Ma     NE     1700.0       350.0            60.0   \n",
       "1    2.5    S      Sa      N     3075.0        60.0            75.0   \n",
       "2    2.0    S      Sa      E     2950.0        40.0            50.0   \n",
       "3    2.5   CS      Sa      E     2170.0        50.0             NaN   \n",
       "4    3.0    S      Ma      W     2465.0       125.0            85.0   \n",
       "..   ...  ...     ...    ...        ...         ...             ...   \n",
       "484                 U               NaN         NaN             NaN   \n",
       "485                 U               NaN         NaN             NaN   \n",
       "486                 U               NaN         NaN             NaN   \n",
       "487                 U               NaN         NaN             NaN   \n",
       "488                Na               NaN         NaN             NaN   \n",
       "\n",
       "    observation_date  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "..               ...  \n",
       "484       1800-01-01  \n",
       "485       1843-12-18  \n",
       "486       1840-02-01  \n",
       "487       1836-02-09  \n",
       "488       1825-02-04  \n",
       "\n",
       "[489 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "# pd.DataFrame(chain.from_iterable(incidents.avalanche_obs)).replace(r'^s*$', float('NaN'), regex = True).dropna()\n",
    "pd.DataFrame(chain.from_iterable(incidents.avalanche_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6a999-029e-4466-9150-75f87401b2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023bbf7c-cb24-4c92-a102-90bc75761f93",
   "metadata": {},
   "source": [
    "## Extracting avalanche accidents in the US "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71ae3b4-4524-4087-8dbc-41ec59fdfe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>ID</td>\n",
       "      <td>Ryan Peak, Idaho</td>\n",
       "      <td>1 skier and 1 snowmobiler killed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>WA</td>\n",
       "      <td>Silver Basin, closed portion of Crystal Mounta...</td>\n",
       "      <td>6 backcountry tourers caught and 1 killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>AK</td>\n",
       "      <td>Ruth Glacier, Denali National Park and Preserve</td>\n",
       "      <td>2 climbers caught in serac fall, 1 killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>AK</td>\n",
       "      <td>Matanuska Glacier</td>\n",
       "      <td>1 heliskier killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>CO</td>\n",
       "      <td>Lime Creek south of Edwards</td>\n",
       "      <td>2 sidecountry skiers caught, 1 buried and killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>CO</td>\n",
       "      <td>Battle Mountain - outside Vail Mountain ski area</td>\n",
       "      <td>1 snowboader caught, partially buried critical...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>MT</td>\n",
       "      <td>Scotch Bonnet Mountain, near Lulu Pass</td>\n",
       "      <td>1 Snowmobiler caught, buried, and killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>OR</td>\n",
       "      <td>Near Paulina Peak</td>\n",
       "      <td>1 Snowmobiler caught, buried, and killed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2009-12-17</td>\n",
       "      <td>ID</td>\n",
       "      <td>Rock Lake, Cascade, Idaho</td>\n",
       "      <td>2 snowmobilers caught, buried, 1 rescued, 1 ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>MT</td>\n",
       "      <td>Hyalite Drainage, northern Gallatins, Bozeman</td>\n",
       "      <td>Hyalite Avalanche Fatality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date State                                           Location  \\\n",
       "0     2021-12-17    ID                                   Ryan Peak, Idaho   \n",
       "1    2021-12-11     WA  Silver Basin, closed portion of Crystal Mounta...   \n",
       "2     2020-05-13    AK    Ruth Glacier, Denali National Park and Preserve   \n",
       "3     2020-03-27    AK                                  Matanuska Glacier   \n",
       "4     2020-03-22    CO                        Lime Creek south of Edwards   \n",
       "..           ...   ...                                                ...   \n",
       "269  2009-01-06     CO   Battle Mountain - outside Vail Mountain ski area   \n",
       "270   2009-01-03    MT             Scotch Bonnet Mountain, near Lulu Pass   \n",
       "271   2009-01-02    OR                                  Near Paulina Peak   \n",
       "272   2009-12-17    ID                          Rock Lake, Cascade, Idaho   \n",
       "273   2009-12-10    MT      Hyalite Drainage, northern Gallatins, Bozeman   \n",
       "\n",
       "                                           Description  Killed  \n",
       "0                     1 skier and 1 snowmobiler killed       2  \n",
       "1            6 backcountry tourers caught and 1 killed       1  \n",
       "2            2 climbers caught in serac fall, 1 killed       1  \n",
       "3                                   1 heliskier killed       1  \n",
       "4     2 sidecountry skiers caught, 1 buried and killed       1  \n",
       "..                                                 ...     ...  \n",
       "269  1 snowboader caught, partially buried critical...       1  \n",
       "270           1 Snowmobiler caught, buried, and killed       1  \n",
       "271           1 Snowmobiler caught, buried, and killed       1  \n",
       "272  2 snowmobilers caught, buried, 1 rescued, 1 ki...       1  \n",
       "273                         Hyalite Avalanche Fatality       1  \n",
       "\n",
       "[274 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "site = \"https://avalanche.org/avalanche-accidents/\"\n",
    "\n",
    "# This is done to prevent 'HTTPError: HTTP Error 403: Forbidden'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "\n",
    "# Prepare soup to access the source code\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "# Scrape the source code to access the source containing the tables\n",
    "soup.find('div', class_='content-area').iframe\n",
    "\n",
    "# Read the cleaned up source and convert it into dataframes \n",
    "df = pd.read_html('https://avalanche.state.co.us/caic/acc/acc_us.php', parse_dates=True)\n",
    "\n",
    "# Only select the useful tables\n",
    "df = df[1::2]\n",
    "\n",
    "# Clean the tables and merge them into one single dataframe representing cases in the US\n",
    "def format_date_col(s, year):\n",
    "    \"\"\"\n",
    "    This function is used to clean the date columns.\n",
    "    It takes a string and cleans the string by removing the dagger sign and\n",
    "    adds the year to the date string.\n",
    "    \"\"\"\n",
    "    month = s.replace('†','').replace('/','-')\n",
    "    year = str(year) + '-'\n",
    "    return year+month\n",
    "\n",
    "years = (2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009)\n",
    "for data, yr in zip(df, years):\n",
    "    data['Date'] = data['Date'].apply(format_date_col, args=[yr])\n",
    "    \n",
    "us_incidents = pd.concat(df).reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "us_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de202bfc-db63-4776-be83-81f4e78ff2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0                       1 skier and 1 snowmobiler killed\n",
       "1              6 backcountry tourers caught and 1 killed\n",
       "2              2 climbers caught in serac fall, 1 killed\n",
       "3                                     1 heliskier killed\n",
       "4       2 sidecountry skiers caught, 1 buried and killed\n",
       "                             ...                        \n",
       "269    1 snowboader caught, partially buried critical...\n",
       "270             1 Snowmobiler caught, buried, and killed\n",
       "271             1 Snowmobiler caught, buried, and killed\n",
       "272    2 snowmobilers caught, buried, 1 rescued, 1 ki...\n",
       "273                           Hyalite Avalanche Fatality\n",
       "Name: Description, Length: 274, dtype: object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_incidents.Description.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3078bdd-9c67-44cb-9be4-57d0f4513127",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Hello, my name is Omer.\"\n",
    "# nltk.tokenize.word_tokenize(txt)\n",
    "tokens = [token for token in nltk.tokenize.word_tokenize(txt)]\n",
    "tokens = [token for token in tokens if not token in stopwords]\n",
    "\n",
    "# len(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords = stopwords.union(set(string.punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb82b0fc-3ecb-4394-ab6a-be5439c843f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                     [1, skier, 1, snowmobiler, killed]\n",
       "1            [6, backcountry, tourer, caught, 1, killed]\n",
       "2           [2, climber, caught, serac, fall, 1, killed]\n",
       "3                                 [1, heliskier, killed]\n",
       "4      [2, sidecountry, skier, caught, 1, buried, kil...\n",
       "                             ...                        \n",
       "269    [1, snowboader, caught, partially, buried, cri...\n",
       "270             [1, snowmobiler, caught, buried, killed]\n",
       "271             [1, snowmobiler, caught, buried, killed]\n",
       "272    [2, snowmobilers, caught, buried, 1, rescued, ...\n",
       "273                       [hyalite, avalanche, fatality]\n",
       "Name: Description, Length: 274, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "# Remove stopwords (the, a, is, etc)\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "# Remove punctuation too (., !, \"\", etc)\n",
    "stopwords=stopwords.union(set(string.punctuation))\n",
    "# Lemmatize words e.g. snowed and snowing are both snow (verb)\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "def text_prep(txt):\n",
    "    soup = BeautifulSoup(txt, \"lxml\")\n",
    "    [s.extract() for s in soup('style')] # remove css\n",
    "    txt=soup.text # remove html tags\n",
    "    txt = txt.lower()\n",
    "    tokens = [token for token in nltk.tokenize.word_tokenize(txt)]\n",
    "    tokens = [token for token in tokens if not token in stopwords]\n",
    "    tokens = [wnl.lemmatize(token) for token in tokens]\n",
    "    if (len(tokens)==0):\n",
    "        tokens = [\"EMPTYSTRING\"]\n",
    "    return(tokens)\n",
    "\n",
    "us_incidents['Description'].apply(text_prep)\n",
    "# text_prep(us_incidents.Description.highlights[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f99a0-93d9-46de-87e1-8dc8c751ab8b",
   "metadata": {},
   "source": [
    "## Extracting avalanche accidents in Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602b46ce-276d-4cc9-a73c-a3c00bf57100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Group Size</th>\n",
       "      <th>Avalanche Comment</th>\n",
       "      <th>Incident Comment</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2782</td>\n",
       "      <td>Mentet</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2021-11-28 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Destructive Avalanche Size of 2.5\"</td>\n",
       "      <td>\"Completely buried. Fatal result. Re-analisis ...</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2781</td>\n",
       "      <td>Val d\\'Ayas, Gran Sommettaz</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2021-11-29 12:05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-piste skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2783</td>\n",
       "      <td>La Thuille</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2021-12-07 13:09:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Backcountry skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>Monte Sorbetta</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2021-12-16 13:04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Backcountry skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1814</td>\n",
       "      <td>Großvenediger</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2020-10-10 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mountaineering/Climbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>149</td>\n",
       "      <td>Mont Brûlé</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2020-05-08 12:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>87</td>\n",
       "      <td>Tofana di Rozes - rifugio Giussani</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-05-09 09:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-piste skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>108</td>\n",
       "      <td>Pizzo del Diavolo/Canalone della Malgina</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-05-12 10:15:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-piste skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180</td>\n",
       "      <td>Gråfonnfjellet</td>\n",
       "      <td>Norway</td>\n",
       "      <td>2020-05-24 12:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Backcountry skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2070</td>\n",
       "      <td>Chamonix, couloir Gervasutti</td>\n",
       "      <td>France</td>\n",
       "      <td>2020-05-31 12:45:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"https:\\/\\/france3-regions.francetvinfo.fr\\/au...</td>\n",
       "      <td>Backcountry skiing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                  Location      Country  \\\n",
       "0   2782                                    Mentet        Spain   \n",
       "1   2781               Val d\\'Ayas, Gran Sommettaz        Italy   \n",
       "2   2783                                La Thuille        Italy   \n",
       "3   2785                            Monte Sorbetta        Italy   \n",
       "0   1814                             Großvenediger      Austria   \n",
       "..   ...                                       ...          ...   \n",
       "35   149                                Mont Brûlé  Switzerland   \n",
       "36    87        Tofana di Rozes - rifugio Giussani        Italy   \n",
       "37   108  Pizzo del Diavolo/Canalone della Malgina        Italy   \n",
       "38   180                            Gråfonnfjellet       Norway   \n",
       "39  2070              Chamonix, couloir Gervasutti       France   \n",
       "\n",
       "                   Date  ... Group Size                    Avalanche Comment  \\\n",
       "0   2021-11-28 00:00:00  ...        1.0  \"Destructive Avalanche Size of 2.5\"   \n",
       "1   2021-11-29 12:05:00  ...        NaN                                  NaN   \n",
       "2   2021-12-07 13:09:00  ...        3.0                                  NaN   \n",
       "3   2021-12-16 13:04:00  ...        2.0                                  NaN   \n",
       "0   2020-10-10 00:00:00  ...        1.0                                  NaN   \n",
       "..                  ...  ...        ...                                  ...   \n",
       "35  2020-05-08 12:00:00  ...        NaN                                  NaN   \n",
       "36  2020-05-09 09:30:00  ...        2.0                                  NaN   \n",
       "37  2020-05-12 10:15:00  ...        1.0                                  NaN   \n",
       "38  2020-05-24 12:00:00  ...        3.0                                  NaN   \n",
       "39  2020-05-31 12:45:00  ...        2.0                                  NaN   \n",
       "\n",
       "                                     Incident Comment                     Type  \n",
       "0   \"Completely buried. Fatal result. Re-analisis ...  Mountaineering/Climbing  \n",
       "1                                                 NaN         Off-piste skiing  \n",
       "2                                                 NaN       Backcountry skiing  \n",
       "3                                                 NaN       Backcountry skiing  \n",
       "0                                                 NaN  Mountaineering/Climbing  \n",
       "..                                                ...                      ...  \n",
       "35                                                NaN                      NaN  \n",
       "36                                                NaN         Off-piste skiing  \n",
       "37                                                NaN         Off-piste skiing  \n",
       "38                                                NaN       Backcountry skiing  \n",
       "39  \"https:\\/\\/france3-regions.francetvinfo.fr\\/au...       Backcountry skiing  \n",
       "\n",
       "[147 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of urls to be read\n",
    "url1 = \"https://www.avalanches.org/fatalities/\"\n",
    "url2 = \"https://www.avalanches.org/fatalities/fatalities-20/\"\n",
    "url3 = \"https://www.avalanches.org/fatalities/fatalities-19/\"\n",
    "urls = [url1, url2, url3]\n",
    "\n",
    "# Scrape the tables from each url and make a list of the tables\n",
    "df = [pd.read_html(url, parse_dates=True) for url in urls]\n",
    "\n",
    "# Make a list of the dataframes within the table list and concat them together to form a single dataframe\n",
    "df = [df[0][0], df[1][0], df[2][0]]\n",
    "eu_incidents = pd.concat(df)\n",
    "\n",
    "eu_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856fcda1-6869-4dea-97be-8cd6954d0dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mountaineering/Climbing', 'Off-piste skiing',\n",
       "       'Backcountry skiing', nan, 'Hiking on foot or snowshoeing',\n",
       "       'Travelling on road', 'On skiruns', 'Snowmobiling', 'Other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_incidents.Type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9366ab-50af-4b8c-a118-f4cd4a54216a",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "note: the 2 websites we chose to use outside of the avalanche canada one were https://avalanche.org/avalanche-accidents/, https://www.avalanches.org/fatalities/fatalities-20/\n",
    "1.  in us accident reports if you click the link on location  it comes up with a list of avalanche details. We can't figure out how to get those into a column to compare. any advice? We are also struggling to scrape the data from the EU site where it says \"details\" under the date so if you have any tips for this as well please let us know. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f49ba",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "For the US, the links to details run some javascript code. This can sometimes require running a full browser with javascript engine to scrape the information. Selenium is the main tool for doing so. Fortunately, there is a simpler way here. \n",
    "\n",
    "If you look at the source of https://avalanche.org/avalanche-accidents/ , you see that all the needed information is in an iframe that contains the url https://avalanche.state.co.us/caic/acc/acc_us.php . Viewing the source of that url reveals that the details pages just have javascript that opens urls like https://avalanche.state.co.us/caic/acc/acc_report.php?acc_id=798&amp;accfm=inv \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cfba8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls of details\n",
    "import re\n",
    "accidents = BeautifulSoup(urlopen('https://avalanche.state.co.us/caic/acc/acc_us.php').read(), \"html.parser\")\n",
    "reporturls = re.findall(\"win=window.open\\('([^']+)'\", accidents.prettify())\n",
    "del reporturls[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2624f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaccidentdetails(url):\n",
    "  url = re.sub('&amp;', '&', url)\n",
    "  soup = BeautifulSoup(urlopen(url).read(), \"html.parser\")\n",
    "  details = dict()\n",
    "  for item in soup.find_all(\"li\", class_=\"acc_rep_list\"):\n",
    "    subi = item.find_all(\"li\")\n",
    "    if (len(subi) > 0):\n",
    "      for subitem in subi:\n",
    "        s = re.split(\":[\\xa0| ]\", subitem.text)\n",
    "        details[s[0]] = s[1]\n",
    "    else:\n",
    "      s = re.split(\":[\\xa0| ]\", item.text)\n",
    "      details[s[0]] = s[1]\n",
    "  return(details)\n",
    "\n",
    "# you might want to organize this differently for throttling and/or caching\n",
    "details = pd.DataFrame([getaccidentdetails(url) for url in reporturls[:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e6f10b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary Description</th>\n",
       "      <th>Primary Activity</th>\n",
       "      <th>Primary Travel Mode</th>\n",
       "      <th>Location Setting</th>\n",
       "      <th>Caught</th>\n",
       "      <th>Partially Buried, Non-Critical</th>\n",
       "      <th>Partially Buried, Critical</th>\n",
       "      <th>Fully Buried</th>\n",
       "      <th>Injured</th>\n",
       "      <th>Killed</th>\n",
       "      <th>Type</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>Trigger (subcode)</th>\n",
       "      <th>Size - Relative to Path</th>\n",
       "      <th>Size - Destructive Force</th>\n",
       "      <th>Sliding Surface</th>\n",
       "      <th>Slope Aspect</th>\n",
       "      <th>Site Elevation</th>\n",
       "      <th>Slope Angle</th>\n",
       "      <th>Slope Characteristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Peak, Idaho</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>\\nUnknown\\n</td>\n",
       "      <td>1 skier and 1 snowmobiler killed</td>\n",
       "      <td>Hybrid Rider</td>\n",
       "      <td>Snowmobile</td>\n",
       "      <td>--</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Basin, closed portion of Crystal Mounta...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 backcountry tourers caught and 1 killed</td>\n",
       "      <td>Backcountry Tourer</td>\n",
       "      <td>Ski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SS</td>\n",
       "      <td>AS - Skier</td>\n",
       "      <td>u - An unintentional release</td>\n",
       "      <td>R3</td>\n",
       "      <td>D2.5</td>\n",
       "      <td>--</td>\n",
       "      <td>NE</td>\n",
       "      <td>6600 ft</td>\n",
       "      <td>35 °</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruth Glacier, Denali National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>\\n5:00 AM\\n(Estimated)</td>\n",
       "      <td>2 climbers caught in serac fall, 1 killed</td>\n",
       "      <td>Climber</td>\n",
       "      <td>Foot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>N -  Natural</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matanuska Glacier</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>\\nUnknown\\n</td>\n",
       "      <td>1 heliskier killed</td>\n",
       "      <td>Mechanised Guiding Client</td>\n",
       "      <td>Ski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lime Creek south of Edwards</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>\\n2:00 PM\\n(Estimated)</td>\n",
       "      <td>2 sidecountry skiers caught, 1 buried and killed</td>\n",
       "      <td>Sidecountry Rider</td>\n",
       "      <td>Ski</td>\n",
       "      <td>Accessed BC from Ski Area</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SS</td>\n",
       "      <td>AS - Skier</td>\n",
       "      <td>u - An unintentional release</td>\n",
       "      <td>R1</td>\n",
       "      <td>D2</td>\n",
       "      <td>G - At Ground/Ice/Firm</td>\n",
       "      <td>NW</td>\n",
       "      <td>9763 ft</td>\n",
       "      <td>45 °</td>\n",
       "      <td>Gully/Couloir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Location       State  \\\n",
       "0                                   Ryan Peak, Idaho       Idaho   \n",
       "1  Silver Basin, closed portion of Crystal Mounta...  Washington   \n",
       "2    Ruth Glacier, Denali National Park and Preserve      Alaska   \n",
       "3                                  Matanuska Glacier      Alaska   \n",
       "4                        Lime Creek south of Edwards    Colorado   \n",
       "\n",
       "                     Time                               Summary Description  \\\n",
       "0             \\nUnknown\\n                  1 skier and 1 snowmobiler killed   \n",
       "1                     NaN         6 backcountry tourers caught and 1 killed   \n",
       "2  \\n5:00 AM\\n(Estimated)         2 climbers caught in serac fall, 1 killed   \n",
       "3             \\nUnknown\\n                                1 heliskier killed   \n",
       "4  \\n2:00 PM\\n(Estimated)  2 sidecountry skiers caught, 1 buried and killed   \n",
       "\n",
       "            Primary Activity Primary Travel Mode           Location Setting  \\\n",
       "0               Hybrid Rider          Snowmobile                         --   \n",
       "1         Backcountry Tourer                 Ski                        NaN   \n",
       "2                    Climber                Foot                        NaN   \n",
       "3  Mechanised Guiding Client                 Ski                        NaN   \n",
       "4          Sidecountry Rider                 Ski  Accessed BC from Ski Area   \n",
       "\n",
       "  Caught Partially Buried, Non-Critical Partially Buried, Critical  \\\n",
       "0      0                              0                          0   \n",
       "1      0                            NaN                        NaN   \n",
       "2      2                            NaN                        NaN   \n",
       "3      0                            NaN                        NaN   \n",
       "4      2                              0                          0   \n",
       "\n",
       "  Fully Buried Injured Killed Type       Trigger  \\\n",
       "0            0       0      2   --            --   \n",
       "1            3       0      1   SS    AS - Skier   \n",
       "2            0       1      1    I  N -  Natural   \n",
       "3            0       0      1   --            --   \n",
       "4            1       0      1   SS    AS - Skier   \n",
       "\n",
       "              Trigger (subcode) Size - Relative to Path  \\\n",
       "0                            --                      --   \n",
       "1  u - An unintentional release                      R3   \n",
       "2                            --                      --   \n",
       "3                            --                      --   \n",
       "4  u - An unintentional release                      R1   \n",
       "\n",
       "  Size - Destructive Force         Sliding Surface Slope Aspect  \\\n",
       "0                       --                      --           --   \n",
       "1                     D2.5                      --           NE   \n",
       "2                       --                      --           --   \n",
       "3                       --                      --           --   \n",
       "4                       D2  G - At Ground/Ice/Firm           NW   \n",
       "\n",
       "  Site Elevation Slope Angle Slope Characteristic  \n",
       "0             --          --                   --  \n",
       "1        6600 ft        35 °                   --  \n",
       "2             --          --                   --  \n",
       "3             --          --                   --  \n",
       "4        9763 ft        45 °        Gully/Couloir  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "  display(details.head())\n",
    "details.to_csv('us_cases_extended.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6070df9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Currently we can't get similar data to that from incidents.avalanche_obs in the Canada Data set from the other 2 data sets. We only have around 150 data points then with a lot of missing values. This question is 2-fold. Is it still possible to run a Prediction model on this smaller amount of data, and if so which would be best? Additionally, if you have any recommendations for getting the similar data from the other 2 sources please let us know. \n",
    "3. which of the items in the plan below should we include to ensure full marks on this project and do you have any suggestions for improvement?\n",
    "\n",
    "4. is there any specific format we need our citations in?\n",
    "\n",
    "## Plan:\n",
    "\n",
    "- investigate frequency of accidents per type of activity \n",
    "    - try to use beautiful soup to rename values in the description for the US data if we can't get the avalanche details thing sorted in question 1\n",
    "    - use beautiful soup to rename values so that Type column in EU matches the activity column in Canada data\n",
    "    - create bar graph\n",
    "- investigate avalanche tendencies by date: See if there is a trend that there are more fatal avalanches later in the ski season than the start\n",
    "    - plot number of deaths as a function of the date, removing the year from the date\n",
    "\n",
    "- compare # of deaths or probability of fatal incident between activities or avalanche size. - will do depending on how data looks.\n",
    "    \n",
    "- prediction analysis:\n",
    "    - use a prediction technique (likely random forests, but will use the answer in question 2)\n",
    "    - as of now will only use avalanche Canada data unless we can scrape the data from US and EU to have the same variables but we are currently lost as to how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd63177-61dd-4a43-8d44-0bf5e23df2e8",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "2. You can run a prediction model with a smaller amount of data. Any method should be okay, but you will need to select less complex models (i.e. fewer features / bigger penalty for lasso, less deep trees). Cross-validation should do this automatically.\n",
    "<br>\n",
    "3. On the one hand, the prediction analysis would use the most ideas from the course. On the other hand, the other three bullets seem to be of more practical use. Both can lead to full marks. Do whatever you find more interesting. <br>\n",
    "I know this is a draft, but for the final version, be sure to add markdown cells between the code saying what you're doing and why.\n",
    "<br>\n",
    "4. I'm happy with anything that includes a url. If there is no url, be sure to have the author(s), title, journal (if applicable), and year.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c212c54",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
